{"componentChunkName":"component---src-templates-blog-post-js","path":"/2023-06-20-Stream-of-NLP/","result":{"data":{"site":{"siteMetadata":{"title":"MediaNavi 미디어나비 Blog"}},"markdownRemark":{"id":"affe0908-debc-569e-bc41-68a6812dbcef","excerpt":"안녕하세요, JUSTA입니다. 이번에 한국언론진흥재단 프로젝트를 했던 인연으로 데이터저널리즘코리아에서 진행하는 5월 세미나에 강사로 발표를 하였답니다. 발표내용은 한국언론진흥재단이 만든 kpf-BERT…","html":"<p>안녕하세요, JUSTA입니다.<br>\n이번에 한국언론진흥재단 프로젝트를 했던 인연으로 데이터저널리즘코리아에서 진행하는 5월 세미나에 강사로 발표를 하였답니다.</p>\n<figure>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/e32b5c6298b13edbccc9afd0bf2fc1d0/ad059/image01.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 116.45569620253164%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAXABQDASIAAhEBAxEB/8QAGAABAQEBAQAAAAAAAAAAAAAAAAIBAwX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAH3JrSgc9Cwf//EABcQAAMBAAAAAAAAAAAAAAAAAAABETD/2gAIAQEAAQUCbhZh/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPwEf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPwEf/8QAGBAAAgMAAAAAAAAAAAAAAAAAAAEwMTL/2gAIAQEABj8Cpsy4P//EABoQAAIDAQEAAAAAAAAAAAAAAAABMUFRECH/2gAIAQEAAT8hc1jDCPBeoc0IQ5Fz/9oADAMBAAIAAwAAABDDxwD/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/EB//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/EB//xAAcEAEBAAMBAAMAAAAAAAAAAAABEQAhMVFBYXH/2gAIAQEAAT8QMAb5EhgSNyXQ19d7igxKWPTErA63lGxZ+OUm8Je3vmS8rPQwk0TP/9k='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"<그림-1> 데이터저널리즘코리아 세미나 초대장 앞면, 이미지 출처 : 데이터저널리즘코리아 운영진\" title=\"<그림-1> 데이터저널리즘코리아 세미나 초대장 앞면, 이미지 출처 : 데이터저널리즘코리아 운영진\" src=\"/static/e32b5c6298b13edbccc9afd0bf2fc1d0/828fb/image01.jpg\" srcset=\"/static/e32b5c6298b13edbccc9afd0bf2fc1d0/ff44c/image01.jpg 158w,\n/static/e32b5c6298b13edbccc9afd0bf2fc1d0/a6688/image01.jpg 315w,\n/static/e32b5c6298b13edbccc9afd0bf2fc1d0/828fb/image01.jpg 630w,\n/static/e32b5c6298b13edbccc9afd0bf2fc1d0/ad059/image01.jpg 758w\" sizes=\"(max-width: 630px) 100vw, 630px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<figcaption>&lt;그림-1&gt; 데이터저널리즘코리아 세미나 초대장 앞면, 이미지 출처 : 데이터저널리즘코리아 운영진</figcaption>\n</figure>  \n<figure>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/1cde331fb7c7e922b9a30ba5e6cbcc3a/ad059/image02.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 109.49367088607596%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAWABQDASIAAhEBAxEB/8QAGQABAAMBAQAAAAAAAAAAAAAAAAEDBQQG/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAdyfPbEdYqqwJB//xAAbEAABBAMAAAAAAAAAAAAAAAABAAIEEAMRI//aAAgBAQABBQK5Ja3JHHBEDdf/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AR//xAAZEAACAwEAAAAAAAAAAAAAAAAQEQABAjL/2gAIAQEABj8COnTmEOaP/8QAHhABAAIBBAMAAAAAAAAAAAAAAQARIRAxQVFhgZH/2gAIAQEAAT8hd+PsA60JrCvqFkYqVEpVfJCgwVLn/9oADAMBAAIAAwAAABD7CAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/EB//xAAWEQEBAQAAAAAAAAAAAAAAAAABESD/2gAIAQIBAT8QG4//xAAdEAEBAAICAwEAAAAAAAAAAAABEQAhMVEQYZHB/9oACAEBAAE/ECc6+McWPt8FQXLd3xPeVW1Y9ir+4QSudqJBcYQAGgNGRn//2Q=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"<그림-2> 데이터저널리즘코리아 세미나 초대장 뒷면, 이미지 출처 : 데이터저널리즘코리아 운영진\" title=\"<그림-2> 데이터저널리즘코리아 세미나 초대장 뒷면, 이미지 출처 : 데이터저널리즘코리아 운영진\" src=\"/static/1cde331fb7c7e922b9a30ba5e6cbcc3a/828fb/image02.jpg\" srcset=\"/static/1cde331fb7c7e922b9a30ba5e6cbcc3a/ff44c/image02.jpg 158w,\n/static/1cde331fb7c7e922b9a30ba5e6cbcc3a/a6688/image02.jpg 315w,\n/static/1cde331fb7c7e922b9a30ba5e6cbcc3a/828fb/image02.jpg 630w,\n/static/1cde331fb7c7e922b9a30ba5e6cbcc3a/ad059/image02.jpg 758w\" sizes=\"(max-width: 630px) 100vw, 630px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<figcaption>&lt;그림-2&gt; 데이터저널리즘코리아 세미나 초대장 뒷면, 이미지 출처 : 데이터저널리즘코리아 운영진</figcaption>\n</figure>  \n<p>발표내용은 한국언론진흥재단이 만든 kpf-BERT 관련 비하인드 스토리와 응용 서비스 개발이지만 아시다시피 요즘 자연어처리에서는 ChatGPT가 모두 집어 삼킨 상황이잖아요?<br>\n그래서 실제로 발표의 초점은 GPT와 대규모언어모델(LLM)의 흐름과 전망으로 잡아보았습니다.</p>\n<p>우리 블로그에도 발 표내용을 대략적으로 정리하는 글을 써보려 하니 모쪼록 도움이 되었으면 좋겠습니다.</p>\n<p>참고로 그사이에도 많은 기술들이 발표되고 있네요.\n관련해서 신기술들 계속 따라갈 수 있게 자주 발행할 수 있도록 하겠습니다.</p>\n<h3><strong>1. 한국언론진흥재단 kpf-BERT 복습</strong></h3>\n<p><strong>1) kpf-BERT 제작</strong></p>\n<figure>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/a46f088dd4e07e886c443cb20ffa4f9a/d4b53/image03.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 46.835443037974684%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe5WiKP/xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAEFAl//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAYEAADAQEAAAAAAAAAAAAAAAAAARAhQf/aAAgBAQABPyEeTg5//9oADAMBAAIAAwAAABDjz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABsQAAEEAwAAAAAAAAAAAAAAAAEAEBExIVGx/9oACAEBAAE/EDkAwLVEbYdKwb//2Q=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"<그림-3> kpf-BERT 성능 측정 결과 비교표, 이미지 출처 : 한국언론진흥재단\" title=\"<그림-3> kpf-BERT 성능 측정 결과 비교표, 이미지 출처 : 한국언론진흥재단\" src=\"/static/a46f088dd4e07e886c443cb20ffa4f9a/828fb/image03.jpg\" srcset=\"/static/a46f088dd4e07e886c443cb20ffa4f9a/ff44c/image03.jpg 158w,\n/static/a46f088dd4e07e886c443cb20ffa4f9a/a6688/image03.jpg 315w,\n/static/a46f088dd4e07e886c443cb20ffa4f9a/828fb/image03.jpg 630w,\n/static/a46f088dd4e07e886c443cb20ffa4f9a/d4b53/image03.jpg 853w\" sizes=\"(max-width: 630px) 100vw, 630px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<figcaption>&lt;그림-3&gt; kpf-BERT 성능 측정 결과 비교표, 이미지 출처 : 한국언론진흥재단</figcaption>\n</figure>  \n<p>이런 성능 좋은 BERT를 한국언론진흥재단에서 만들었었죠.\n그 당시 최신의 기술(Distilbert 등)이 가미되고, 정제된 신문기사 데이터가 학습되어 좀 더 좋은 성능이 나왔을 것으로 생각됩니다.</p>\n<p>관심 있으시면 아래 링크로…<br>\n<a href=\"https://github.com/KPFBERT/kpfbert\">https://github.com/KPFBERT/kpfbert</a> 깃헙 모델저장 링크<br>\n<a href=\"https://youtu.be/Pj6563CAnKs\">https://youtu.be/Pj6563CAnKs</a> BERT란 무엇인가</p>\n<p><strong>2) 응용 서비스 예제</strong>\n응용 서비스에 활용할 수 있는 예제소스도 아래와 같이 공개되어 있습니다.<br>\n<a href=\"https://github.com/KPFBERT/kpfSBERT\">https://github.com/KPFBERT/kpfSBERT</a> 문장임베딩 BERT<br>\n<a href=\"https://github.com/KPFBERT/kpfSBERT_Clustering\">https://github.com/KPFBERT/kpfSBERT_Clustering</a>   클러스터링<br>\n<a href=\"https://github.com/KPFBERT/kpfbertsum\">https://github.com/KPFBERT/kpfbertsum</a> 텍스트 요약 예제</p>\n<p>여기까지가 벌써 2년 전 일이네요.\n요즘 인공지능의 발전속도는 자고 일어나면 세상이 변해있는 수준이죠.<br>\n2년 전이면… 이제는 유물이 된 것 같은 느낌이네요.</p>\n<p>서론에 말씀드린 것처럼 요즘 대세는 ChatGPT이죠. 그래서 이제 GPT, LLM, 그 틈새 기술과 전망에 대해 이야기 해보죠.</p>\n<figure>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 189px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/deb828ec61c64740886cbcd79d0b3b05/bd682/image04.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 100.63291139240506%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGQABAAMBAQAAAAAAAAAAAAAAAAIDBAEF/8QAFgEBAQEAAAAAAAAAAAAAAAAAAQAC/9oADAMBAAIQAxAAAAHNKy/F5ja0RtF4C//EABsQAAICAwEAAAAAAAAAAAAAAAECABIDERMy/9oACAEBAAEFAtEBUaPYM2TRRr4+lYECN5ljP//EABYRAQEBAAAAAAAAAAAAAAAAAAERIP/aAAgBAwEBPwFJj//EABcRAAMBAAAAAAAAAAAAAAAAAAACEBH/2gAIAQIBAT8BQy//xAAgEAABAgUFAAAAAAAAAAAAAAABADECAxESURAhIkFC/9oACAEBAAY/Au0AYnZULoQS9yqwvjC5S7jkhXByjT0+n//EABsQAQADAQEBAQAAAAAAAAAAAAEAETEhQVGB/9oACAEBAAE/IVlGvqFhFNF+lxOVBzZxh35cRcJr1Eqvt7Ys4wNt6Rl//9oADAMBAAIAAwAAABB0KP3/xAAXEQADAQAAAAAAAAAAAAAAAAAAASEQ/9oACAEDAQE/EEwmXf/EABcRAQADAAAAAAAAAAAAAAAAAAEAEBH/2gAIAQIBAT8QCmpZn//EABsQAQACAwEBAAAAAAAAAAAAAAEAESExQWFx/9oACAEBAAE/ELgztOhjAC7xQHt8JmLaBVKgq04adzJVTTyGyuRpcc7h54aPkOVsXnXyJTKb1ZZuy3eD5P/Z'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"<그림-4> kpf-BERT 토닥토닥..., 이미지 출처 : https://m.animalplanet.co.kr/contents/?artNo=8657\" title=\"<그림-4> kpf-BERT 토닥토닥..., 이미지 출처 : https://m.animalplanet.co.kr/contents/?artNo=8657\" src=\"/static/deb828ec61c64740886cbcd79d0b3b05/bd682/image04.jpg\" srcset=\"/static/deb828ec61c64740886cbcd79d0b3b05/ff44c/image04.jpg 158w,\n/static/deb828ec61c64740886cbcd79d0b3b05/bd682/image04.jpg 189w\" sizes=\"(max-width: 189px) 100vw, 189px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<figcaption> &lt;그림-4&gt; kpf-BERT 토닥토닥, 이미지 출처 : https://m.animalplanet.co.kr/contents/?artNo=8657</figcaption>\n</figure>\n<h3><strong>2. LLM - ChatGPT 공주와 일곱 난쟁이들</strong></h3>\n<figure>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/db3d25c3f9ca58632183a087ae28c774/3c4de/image05.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAMEBQH/xAAYAQACAwAAAAAAAAAAAAAAAAAAAQIDBP/aAAwDAQACEAMQAAAB1eVo8711RaW4CSlAf//EABwQAAICAgMAAAAAAAAAAAAAAAECAAMRIRMiMv/aAAgBAQABBQJ7IlmKxsHT+ZUeuBOFMhAs/8QAFxEAAwEAAAAAAAAAAAAAAAAAAAEREP/aAAgBAwEBPwGMm//EABoRAAEFAQAAAAAAAAAAAAAAAAABAhAREiH/2gAIAQIBAT8B0I7hUf/EABsQAAMAAgMAAAAAAAAAAAAAAAABESExAhAS/9oACAEBAAY/AnxVE3eoeVYZTNGjB//EABwQAQACAwEBAQAAAAAAAAAAAAEAESExUYFhcf/aAAgBAQABPyG5Cnp2HsL2Kh7DZSsuY92mY+6bizaHyKJ2fsKoUfs//9oADAMBAAIAAwAAABDf50P/xAAXEQADAQAAAAAAAAAAAAAAAAAAAREQ/9oACAEDAQE/ECorz//EABkRAQEAAwEAAAAAAAAAAAAAAAEAESExwf/aAAgBAgEBPxDLa98swWQ9IAv/xAAbEAEBAQEBAQEBAAAAAAAAAAABESEAMUFRwf/aAAgBAQABPxCIVpjseb15bbhmM+cIIgKUj3xEBW0vu+dYFQiEgPo8pqZ66/mzlyZ9UdeEWrX9691Li97/2Q=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"<그림-5> ChatGPT 공주와 일곱 난쟁이들, 이미지 출처 : 디즈니 애니메이션 백설공주와 일곱 난쟁이 중 편집\" title=\"<그림-5> ChatGPT 공주와 일곱 난쟁이들, 이미지 출처 : 디즈니 애니메이션 백설공주와 일곱 난쟁이 중 편집\" src=\"/static/db3d25c3f9ca58632183a087ae28c774/828fb/image05.jpg\" srcset=\"/static/db3d25c3f9ca58632183a087ae28c774/ff44c/image05.jpg 158w,\n/static/db3d25c3f9ca58632183a087ae28c774/a6688/image05.jpg 315w,\n/static/db3d25c3f9ca58632183a087ae28c774/828fb/image05.jpg 630w,\n/static/db3d25c3f9ca58632183a087ae28c774/3c4de/image05.jpg 756w\" sizes=\"(max-width: 630px) 100vw, 630px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<figcaption> &lt;그림-5&gt; ChartGPT 백설공주와 일곱난쟁이들, 이미지 출처 : 디즈니 애니메이션 \"백설공주와 일곱 난쟁이\" 중 편집</figcaption>\n</figure>  \n<p>자, 요즘 대규모언어모델의 분위기를 어떻게 표현해 볼 수 있을까 하다가 선택한 그림입니다. 백설공주와 일곱 난쟁이들.\n딱 맞는 상황은 아니겠지만, 어쨌든 ChatGPT가 1-TOP으로 시장을 평정했고, 그 와중에 소규모 로컬 LLM들이 우후죽순 생겨나고 있지요.</p>\n<p>아래 막대 그래프는 최근에 나와있는 로컬 LLM 모델들을 비교해 놓았길래, 어떤 모델들이 있는지 보기 편해서 가져와 봤습니다. 7개가 훨씬 넘네요.ㅎㅎ</p>\n<figure>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/b6367303d5158fc775e78c78f0d8c4bb/ad059/image06.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 191.13924050632912%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAmABQDASIAAhEBAxEB/8QAGAABAQEBAQAAAAAAAAAAAAAAAAUEAgP/xAAWAQEBAQAAAAAAAAAAAAAAAAACAQD/2gAMAwEAAhADEAAAAbeHbgIoulXnLqS1rIl4zEWwU//EAB0QAAICAgMBAAAAAAAAAAAAAAECAzIAIRAREyL/2gAIAQEAAQUCkqrNidlZKKdDQkp9HiWik+mPWNCrZ//EABoRAAICAwAAAAAAAAAAAAAAAAEQIfACEUH/2gAIAQMBAT8By3xWygIX/8QAGBEBAAMBAAAAAAAAAAAAAAAAARARIEH/2gAIAQIBAT8BVgvhj//EAB0QAAIBBAMAAAAAAAAAAAAAAAABEAIRIUIxMlH/2gAIAQEABj8COpkZtDllKTfPkWNY/8QAIRABAAIBAwQDAAAAAAAAAAAAAQARIRAxoUFRYZHR4fD/2gAIAQEAAT8hVNC0lL4fUQHcziQur2hpLuJIl5WNOFMWF/G2ma7oJxTwZlz/2gAMAwEAAgADAAAAEGcw/AwP/8QAHBEBAAEEAwAAAAAAAAAAAAAAAQAQESFhgeHw/9oACAEDAQE/EEOkL2zM69woSlKf/8QAGREAAwADAAAAAAAAAAAAAAAAAAExIFFx/9oACAECAQE/EFIKGsfcP//EAB4QAQEAAgEFAQAAAAAAAAAAAAERACExEEFRkdGh/9oACAEBAAE/EELAKau/TjktNtvAnzZMjeptxlz8z9zaaDlauM5tinrG5IoSH3DA1LpbC46NC9vPnoE4FM3xjCyi3wOj/9k='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"<그림-6> LLMs vs. Double Jeopardy, 이미지 출처 : https://www.reddit.com/r/LocalLLaMA/comments/13hd8dt/llm_double_jeopardy_testing_with_new_models/\" title=\"<그림-6> LLMs vs. Double Jeopardy, 이미지 출처 : https://www.reddit.com/r/LocalLLaMA/comments/13hd8dt/llm_double_jeopardy_testing_with_new_models/\" src=\"/static/b6367303d5158fc775e78c78f0d8c4bb/828fb/image06.jpg\" srcset=\"/static/b6367303d5158fc775e78c78f0d8c4bb/ff44c/image06.jpg 158w,\n/static/b6367303d5158fc775e78c78f0d8c4bb/a6688/image06.jpg 315w,\n/static/b6367303d5158fc775e78c78f0d8c4bb/828fb/image06.jpg 630w,\n/static/b6367303d5158fc775e78c78f0d8c4bb/ad059/image06.jpg 758w\" sizes=\"(max-width: 630px) 100vw, 630px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<figcaption>&lt;그림-6&gt; LLMs vs. Double Jeopardy, 이미지 출처 : https://www.reddit.com/r/LocalLLaMA/comments/13hd8dt/llm_double_jeopardy_testing_with_new_models/</figcaption>\n</figure>  \n<p>그럼 왜 갑자기 언어모델이 인공지능 판에서 메인이 되었을까요?</p>\n<p><strong>1) AI와 NLP, 그리고 AGI</strong></p>\n<p>최초에 인공지능은 인간과 동등한 수준의 일반인공지능(AGI, Artficial General Intelligence, 강인공지능이라고 불리기도 함)의 구현이 목표였으나, 과거의 기술과 장비로는 불가능함을 깨닫고 각각의 소분류별 쓰임에 따라 발전해오고 있었죠.</p>\n<p>비전이나 음성처럼 언어도 NLP(자연어처리)라는 한 분야로서 시작했는데, 성능이 발전할수록, 지금의 ChatGPT에 이르러서는 그 자체로 AGI의 가능성을 보이는 겁니다.</p>\n<p>언어를 깊게 이해하면 그 자체가 지능이 될 수 있는것 아닌가하는 가능성을 보여주는 수준에 이른 것이지요.</p>\n<p><strong>2) LLM의 눈부신 발전 - 클수록 좋다!</strong></p>\n<p>LLM(Large Language Model)은 말 그대로 거대언어모델입니다.\n거대한 사이즈와 거대한 학습량을 기반으로 큰 성능향상을 이룬면서 생긴 트랜드이지요.</p>\n<p>GPT3를 기점으로 모델 사이즈가 크면 클수록 좋은 성능이 나온다는 흐름이 있었습니다.</p>\n<p>이후 학습데이터의 양이 많을수록 좋은 성능이 나온다는 주장도 생겼죠.</p>\n<p>하단의 참고 이미지를 보시면 거대한 사이즈의 전쟁이 벌어진 것을 알 수 있습니다.</p>\n<figure>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/469fad12eeb5a85ed46ffea568a96dd2/ad059/image07.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 56.32911392405063%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAQFAgP/xAAWAQEBAQAAAAAAAAAAAAAAAAACAAH/2gAMAwEAAhADEAAAAX1uGEaxILf/xAAaEAADAQADAAAAAAAAAAAAAAAAAQITAxIh/9oACAEBAAEFAvOzOJpTtZrZtZ//xAAXEQEAAwAAAAAAAAAAAAAAAAAAARFh/9oACAEDAQE/AZxb/8QAFhEAAwAAAAAAAAAAAAAAAAAAARAx/9oACAECAQE/ARV//8QAHBAAAgICAwAAAAAAAAAAAAAAAAExoQIREiEy/9oACAEBAAY/AuKwY9dntE0TRNH/xAAfEAEAAgEDBQAAAAAAAAAAAAABABEhMUGRUWFxscH/2gAIAQEAAT8hc9gb7VG8sr1KWmua6douPylGQHgRt08J/9oADAMBAAIAAwAAABBoH//EABkRAAMAAwAAAAAAAAAAAAAAAAABESFRkf/aAAgBAwEBPxCMQuC0P//EABkRAQACAwAAAAAAAAAAAAAAAAEAETFRof/aAAgBAgEBPxCwlXG+xLbn/8QAHhABAAICAgMBAAAAAAAAAAAAAQARITFBkWFxobH/2gAIAQEAAT8QYzw2lwabuYwOdVuDt7lzcDxu4Oz5lkFsp5DqXhYaofhLZyO3Z8n/2Q=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"<그림-7> LANGUAGE MODEL SIZES TO DEC/2022, 이미지 출처 : https://www.reddit.com/r/mlscaling/comments/wizfmm/language_model_sizes_to_aug2022/\" title=\"<그림-7> LANGUAGE MODEL SIZES TO DEC/2022, 이미지 출처 : https://www.reddit.com/r/mlscaling/comments/wizfmm/language_model_sizes_to_aug2022/\" src=\"/static/469fad12eeb5a85ed46ffea568a96dd2/828fb/image07.jpg\" srcset=\"/static/469fad12eeb5a85ed46ffea568a96dd2/ff44c/image07.jpg 158w,\n/static/469fad12eeb5a85ed46ffea568a96dd2/a6688/image07.jpg 315w,\n/static/469fad12eeb5a85ed46ffea568a96dd2/828fb/image07.jpg 630w,\n/static/469fad12eeb5a85ed46ffea568a96dd2/ad059/image07.jpg 758w\" sizes=\"(max-width: 630px) 100vw, 630px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<figcaption>&lt;그림-7&gt; LANGUAGE MODEL SIZES TO DEC/2022, 이미지 출처 : https://www.reddit.com/r/mlscaling/comments/wizfmm/language_model_sizes_to_aug2022/</figcaption>\n</figure>  \n<p>하지만 크다고 무조건 성능이 좋다는 것은 아닌 것으로 밝혀지며 지각변동이 생깁니다.</p>\n<p>OpenAI가 잘 정제된 데이터에 인간의 피드백을 추가해 학습한 ChatGPT라는 월등한 성능의 모델을 내 놓게 되면서 크기경쟁은 일단락 되는데요.</p>\n<p>다들 잘 알고 계시리라 생각되어 일단 ChatGPT의 설명은 생략하겠습니다.</p>\n<p>하지만 ChatGPT의 등장은 새로운 언어모델 학습의 길을 만들어주게 됩니다.</p>\n<p>바로 로컬 LLM의 등장을 가속화하는 계기가 된 것입니다.</p>\n<p><strong>3) sLLM의 반격 - 작은 것도 충분히 좋다!</strong></p>\n<p>sLLM(Small Large Language Model)이라는 모순적인 용어로도 불리는 로컬LLM모델은 아이러니하게 ChatGPT 덕분에 저렴하게 고성능으로 학습할 수 있게 되었습니다. 바로 ChatGPT에 질문과 답변을 받아내어 학습데이터로 사용하는 것이지요.</p>\n<p>이로써 ChatGPT 학습에 사용된 데이터 가공 비용에 비하면 거의 공짜나 다름없는 비용으로 아주 양질의 학습데이터를 방대하게 만들어 쓸 수 있게 된 것이죠.</p>\n<figure>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/30552d82d4e79cc1011ff87e43e5dcf1/ad059/image08.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 43.67088607594937%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIDBf/EABUBAQEAAAAAAAAAAAAAAAAAAAEA/9oADAMBAAIQAxAAAAHaWiFUkJ//xAAZEAEAAgMAAAAAAAAAAAAAAAABAAIQEjH/2gAIAQEAAQUCbJHaHM//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAYEAACAwAAAAAAAAAAAAAAAAABAhAgIf/aAAgBAQAGPwLFgU//xAAZEAACAwEAAAAAAAAAAAAAAAABEQAhMRD/2gAIAQEAAT8hqCHIb1iMe7V0T//aAAwDAQACAAMAAAAQ6P8A/8QAFxEAAwEAAAAAAAAAAAAAAAAAARARMf/aAAgBAwEBPxA5F//EABYRAQEBAAAAAAAAAAAAAAAAABEAIf/aAAgBAgEBPxA1i//EABwQAAICAgMAAAAAAAAAAAAAAAERADEhQRBRkf/aAAgBAQABPxAkUOzwXfkWB7JA2sTdcDffBuUn/9k='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"<그림-8> GPT-4 grades LLM output, 이미지 출처 : https://vicuna.lmsys.org/\" title=\"<그림-8> GPT-4 grades LLM output, 이미지 출처 : https://vicuna.lmsys.org/\" src=\"/static/30552d82d4e79cc1011ff87e43e5dcf1/828fb/image08.jpg\" srcset=\"/static/30552d82d4e79cc1011ff87e43e5dcf1/ff44c/image08.jpg 158w,\n/static/30552d82d4e79cc1011ff87e43e5dcf1/a6688/image08.jpg 315w,\n/static/30552d82d4e79cc1011ff87e43e5dcf1/828fb/image08.jpg 630w,\n/static/30552d82d4e79cc1011ff87e43e5dcf1/ad059/image08.jpg 758w\" sizes=\"(max-width: 630px) 100vw, 630px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<figcaption>&lt;그림-8&gt; GPT-4 grades LLM output, 이미지 출처 : https://vicuna.lmsys.org/</figcaption>\n</figure>  \n<p>위 표를 보면 성능비교의 기준점이 ChatGPT가 되어버렸네요. 너도 나도 모델을 내놓을 때 “ChatGPT 보다 뛰어나다” 또는 “몇% 성능이다” 라고 하는 세상입니다.</p>\n<p>로컬LLM이 ChatGPT 대비 성능이 잘 나오는 이유 중엔 ChatGPT가 생성한 데이터를 쓴 영향도 존재하는 것이죠.</p>\n<p>물론 성능은 ChatGPT가 여전히 압도적으로 좋습니다만, 로컬모델도 나름대로의 필요성에 의해 만들어지고 있습니다.</p>\n<p>앞에서 ChatGPT 공주와 일곱 난쟁이 중에 첫째 난쟁이로 LLaMA를 꼽았습니다.</p>\n<p>META(구 페이스북)에서 개발하여 공개(?)당한 로컬LLM모델입니다.</p>\n<p>META는 이것을 오픈소스로 공개하기는 했는데, 학술목적으로 waitlist 신청을 받아서 순차적으로 조금씩 공개하고 있었습니다.</p>\n<p>그런데, 어떤 유저가 이 모델을 받아서 토랜트로 풀어버립니다.</p>\n<p>이로써 강제공개(?)…<br>\n※ 하지만 META는 OpenAI(라 쓰고 ClosedAI라고 읽는다!)보다 훨씬 OPEN된 마인드로 기술들을 공개하고 있으니 많이 칭찬해 주세요~</p>\n<p>이때부터 sLLM의 꽃이 피기 시작했다고 할 만한 상황으로 발전하였고, 제가 난장이 중 첫 번째의 영광을 주었습니다.^^</p>\n<p>여기에 채팅식 문답가공 파인튜닝과 인스트럭션 튜닝을 거친 Alpaca나 Vicuna 등의 모델들이 나오며 sLLM모델의 기술과 기법들이 빠르게 발전하였습니다.</p>\n<h3><strong>3. 로컬 LLM 모델의 가능성과 활용</strong></h3>\n<p>그러면 강력한 성능의 ChatGPT를 API로 이용하면 될텐데, 왜 로컬언어모델을 쓸까요?</p>\n<p>ChatGPT의 일반적인 강력한 성능은 너무나 좋지만 모든경우에 적용하기는 부적절한 경우가 존재합니다.</p>\n<p>의료나 법률처럼 일반적인 지식은 필요없고, 특수한 도메인에 국한된 서비스만 필요하다면 ChatGPT는 너무 거대할 수도 있죠.</p>\n<p>마치 아래 이미지와 같이 닭 잡는데 소 잡는 칼을 쓰는 것처럼요.</p>\n<figure>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/8b9974b0ab33ef20b6ae7ef594236548/ad059/image09.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 95.56962025316456%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAATABQDASIAAhEBAxEB/8QAGAABAQEBAQAAAAAAAAAAAAAAAAMEAgX/xAAVAQEBAAAAAAAAAAAAAAAAAAABAP/aAAwDAQACEAMQAAAB860qT0yq06gbAf/EABsQAAICAwEAAAAAAAAAAAAAAAECAxEAEiEi/9oACAEBAAEFArohheRqZCYyo1kbF4VO7yeG/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPwEf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPwEf/8QAGxAAAgMAAwAAAAAAAAAAAAAAAAECESEQEpH/2gAIAQEABj8CwrjqWtLSfhhBS1FRdI//xAAZEAEBAQEBAQAAAAAAAAAAAAABEQAxQVH/2gAIAQEAAT8hvRTib3cQHy6S+4vzdBj8xLVMjpRKZttCy7//2gAMAwEAAgADAAAAEOjHvP/EABcRAQADAAAAAAAAAAAAAAAAAAEAEDH/2gAIAQMBAT8QLMn/xAAYEQEBAAMAAAAAAAAAAAAAAAABABARIf/aAAgBAgEBPxDlswhf/8QAGxABAAMBAQEBAAAAAAAAAAAAAQARITFBcVH/2gAIAQEAAT8QtRBd+272Xv3RPoRVUMCj1bfwyb9voDwPSF5uOskuOy8mlsQoe7kx+yhdZ//Z'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"<그림-09> 닭 잡는데 소 잡는 칼을 쓰는 꼴을 설명하는 이미지, 이미지 출처 : https://twitter.com/dev_humor/status/1081973719801712640\" title=\"<그림-09> 닭 잡는데 소 잡는 칼을 쓰는 꼴을 설명하는 이미지, 이미지 출처 : https://twitter.com/dev_humor/status/1081973719801712640\" src=\"/static/8b9974b0ab33ef20b6ae7ef594236548/828fb/image09.jpg\" srcset=\"/static/8b9974b0ab33ef20b6ae7ef594236548/ff44c/image09.jpg 158w,\n/static/8b9974b0ab33ef20b6ae7ef594236548/a6688/image09.jpg 315w,\n/static/8b9974b0ab33ef20b6ae7ef594236548/828fb/image09.jpg 630w,\n/static/8b9974b0ab33ef20b6ae7ef594236548/ad059/image09.jpg 758w\" sizes=\"(max-width: 630px) 100vw, 630px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<figcaption>&lt;그림-9&gt; 이미지 출처 : https://twitter.com/dev_humor/status/1081973719801712640/</figcaption>\n</figure>\n<p>가령 어떤 기업이 내부의 기밀자료를 파인튜닝 시켜서 업무에 활용하고 싶다고 하면, ChatGPT에게 그 자료를 학습시켜서 이용하기는 부담스러울 겁니다. 회사 내부망에서만 접근 가능한 로컬LLM모델을 활용하여 구현하는게 자연스럽죠.</p>\n<p>꼭 보안자료가 아니라도 사용량만큼 과금되는 ChatGPT API를 이용하여 서비스를 했을때 그 사용량이 아주 많아진다면 비용상의 문제로도 자신들의 서비스 내에 직접 로컬LLM모델을 사용할 수 밖에 없을 겁니다.</p>\n<p>또한 개인이 개인적으로 모델을 파인튜닝하여 사용하고 싶을때도 로컬LLM을 쓰게 될 것이구요.</p>\n<p>자꾸 학습, 또는 파인튜닝 이야기가 나와서 요즘 LLM에서 학습이 진행되는 단계에 대해 잠깐 언급해 보도록 할게요.</p>\n<p>단계별로 나눠본다면 총 4단계로 나눌 수 있을 것 같아요.</p>\n<table>\n<thead>\n<tr>\n<th>분 류</th>\n<th>단 계</th>\n<th>상세 설명</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>1단계</td>\n<td>사전학습(pretrain)</td>\n<td>가능한 많은 데이터를 집어 넣어서 언어를 이해시키는 단계</td>\n</tr>\n<tr>\n<td>2단계</td>\n<td>DAPT(Domain Adaptive PreTraining)</td>\n<td>활용하고자 하는 도메인에 한정된 데이터를 추가로 학습시켜 해당도메인에 대한 성능을 향상시키는 단계</td>\n</tr>\n<tr>\n<td>3단계</td>\n<td>TAPT(Task Adaptive PreTraining)</td>\n<td>도메인 내에서도 실제로 하고자 하는 테스크에 맞춘 데이터셋으로 파인튜닝하는 단계</td>\n</tr>\n<tr>\n<td>4단계</td>\n<td>미세파인튜닝(personalize)</td>\n<td>LORA 같은 추가 튜닝모델을 덧붙여서 개별화 또는 특화시키는 파인튜닝 기법</td>\n</tr>\n</tbody>\n</table>\n<p>&#x3C;표-1> LLM에서 학습의 진행단계별 분류</p>\n<figure>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/1bc39813d0060a827294f12774648f60/ad059/image10.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 70.88607594936708%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAMC/8QAFgEBAQEAAAAAAAAAAAAAAAAAAAED/9oADAMBAAIQAxAAAAHa2WtFCf/EABkQAAIDAQAAAAAAAAAAAAAAAAECAAMREv/aAAgBAQABBQKwvq9RWOMpDYTK6yV//8QAFxEAAwEAAAAAAAAAAAAAAAAAARARIf/aAAgBAwEBPwG5AF//xAAWEQADAAAAAAAAAAAAAAAAAAAQESH/2gAIAQIBAT8BrH//xAAZEAABBQAAAAAAAAAAAAAAAAAAECEiMUH/2gAIAQEABj8CYkWYv//EABoQAAMBAQEBAAAAAAAAAAAAAAABETEhUXH/2gAIAQEAAT8hYa9e0ZVKv0V4bRoXoeqFRUun/9oADAMBAAIAAwAAABCz7//EABkRAQACAwAAAAAAAAAAAAAAAAEAETFBcf/aAAgBAwEBPxBdAdlm8z//xAAZEQADAAMAAAAAAAAAAAAAAAAAAREhMWH/2gAIAQIBAT8QTtqTAun/xAAdEAEAAwABBQAAAAAAAAAAAAABABEhQTFhgdHx/9oACAEBAAE/ELWFUtyvpEFIcw/DndNzKWvyOaXl9RUDWzWf/9k='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"<그림-10> LLM에서 학습 진행단계별 분류 설명 이미지, 이미지 출처 : JUSTA 제작\" title=\"<그림-10> LLM에서 학습 진행단계별 분류 설명 이미지, 이미지 출처 : JUSTA 제작\" src=\"/static/1bc39813d0060a827294f12774648f60/828fb/image10.jpg\" srcset=\"/static/1bc39813d0060a827294f12774648f60/ff44c/image10.jpg 158w,\n/static/1bc39813d0060a827294f12774648f60/a6688/image10.jpg 315w,\n/static/1bc39813d0060a827294f12774648f60/828fb/image10.jpg 630w,\n/static/1bc39813d0060a827294f12774648f60/ad059/image10.jpg 758w\" sizes=\"(max-width: 630px) 100vw, 630px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<figcaption>&lt;그림-10&gt; LLM에서 학습 진행단계별 분류 설명 이미지, 이미지 출처 : JUSTA 작성</figcaption>\n</figure>\n<p>정형화된 건 아니지만 이런 단계를 거쳐서 서비스에 활용하게 될 것입니다.</p>\n<p>그리고 LLM의 종착역은 맞춤형 인공지능 개인비서가 아닐까 합니다.</p>\n<p>인공지능 개인비서 하니 가장 먼저 떠오르는 것은 영화 “아이언맨”의 자비스가 아닐까 싶네요.</p>\n<figure>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/2af1a6a3b098f27752a20aadf7435069/ad059/image11.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 60.12658227848101%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAMFAv/EABcBAAMBAAAAAAAAAAAAAAAAAAABAgP/2gAMAwEAAhADEAAAAUbqJHPKZWf/xAAbEAADAAIDAAAAAAAAAAAAAAABAgMABBITFP/aAAgBAQABBQI1p2PSnGZu6nVQp45YNWYH/8QAFxEBAAMAAAAAAAAAAAAAAAAAAAECEf/aAAgBAwEBPwGG2f/EABURAQEAAAAAAAAAAAAAAAAAAAAh/9oACAECAQE/AUf/xAAcEAABBAMBAAAAAAAAAAAAAAAAAQMRIRIxQZH/2gAIAQEABj8ChHFsp3wlHoMLjZ06f//EAB0QAAICAwADAAAAAAAAAAAAAAABEUEhUWExkaH/2gAIAQEAAT8haREtq+Em/DTLIvxHWZIiehdXpHkvY//aAAwDAQACAAMAAAAQcx//xAAXEQADAQAAAAAAAAAAAAAAAAAAASER/9oACAEDAQE/EGlHpMP/xAAWEQEBAQAAAAAAAAAAAAAAAAABADH/2gAIAQIBAT8Qdgv/xAAeEAEBAAEDBQAAAAAAAAAAAAABEQAxUbEhQXGB0f/aAAgBAQABPxBJdOqj2VBziAoiUFdjKdBkm8YUQSI1ZNZgMGt7+emTmF2fM//Z'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"<그림-11> 그냥 좀 많이 똑똑한 시스템(Just A Rather Very Intelligent System), 이미지 출처 : 미디엄 게시글/디즈니 마블 스튜디오(영화 아이언맨)\" title=\"<그림-11> 그냥 좀 많이 똑똑한 시스템(Just A Rather Very Intelligent System), 이미지 출처 : 미디엄 게시글/디즈니 마블 스튜디오(영화 아이언맨)\" src=\"/static/2af1a6a3b098f27752a20aadf7435069/828fb/image11.jpg\" srcset=\"/static/2af1a6a3b098f27752a20aadf7435069/ff44c/image11.jpg 158w,\n/static/2af1a6a3b098f27752a20aadf7435069/a6688/image11.jpg 315w,\n/static/2af1a6a3b098f27752a20aadf7435069/828fb/image11.jpg 630w,\n/static/2af1a6a3b098f27752a20aadf7435069/ad059/image11.jpg 758w\" sizes=\"(max-width: 630px) 100vw, 630px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<figcaption>&lt;그림-11&gt;그냥 좀 많이 똑똑한 시스템(Just A Rather Very Intelligent System), 이미지 출처 : 미디엄 게시글/디즈니 마블 스튜디오(영화 \"아이언맨\")</figcaption>\n</figure>  \n<p>자비스의 어원을 알고 계셨나요? 전 이번에 알아서 좀 충격이었네요.ㅎㅎ</p>\n<p>궁극적으로 LLM이 개인비서 형태의 서비스로 발전하게 되면 아무래도 로컬 디바이스에 설치된 로컬서비스 형태로 구현될 것입니다.</p>\n<p>영화 “HER” 처럼요.</p>\n<figure>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/784092f145451884ce29b4a769e99439/ad059/image12.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 43.0379746835443%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAgADBP/EABUBAQEAAAAAAAAAAAAAAAAAAAIB/9oADAMBAAIQAxAAAAHLgRDEKn//xAAbEAACAQUAAAAAAAAAAAAAAAABAgADEBEhMf/aAAgBAQABBQLTKBlZT4Lf/8QAFhEAAwAAAAAAAAAAAAAAAAAAARAx/9oACAEDAQE/ARV//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFhABAQEAAAAAAAAAAAAAAAAAEQEQ/9oACAEBAAY/AqBt3//EABsQAAMAAgMAAAAAAAAAAAAAAAABERBBMXGh/9oACAEBAAE/Ia7WCcjLBztLs8DN8f/aAAwDAQACAAMAAAAQxy//xAAXEQADAQAAAAAAAAAAAAAAAAAAAREh/9oACAEDAQE/EJekU//EABcRAQADAAAAAAAAAAAAAAAAAAABETH/2gAIAQIBAT8QyFP/xAAcEAEAAgMAAwAAAAAAAAAAAAABABEhQVExcfD/2gAIAQEAAT8QEh3TMY2QkNWpVwMkBxT6HJ4e82z/2Q=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"<그림-12> 이미지 출처 : 영화 <HER> 장면 중 편집\" title=\"<그림-12> 이미지 출처 : 영화 <HER> 장면 중 편집\" src=\"/static/784092f145451884ce29b4a769e99439/828fb/image12.jpg\" srcset=\"/static/784092f145451884ce29b4a769e99439/ff44c/image12.jpg 158w,\n/static/784092f145451884ce29b4a769e99439/a6688/image12.jpg 315w,\n/static/784092f145451884ce29b4a769e99439/828fb/image12.jpg 630w,\n/static/784092f145451884ce29b4a769e99439/ad059/image12.jpg 758w\" sizes=\"(max-width: 630px) 100vw, 630px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<figcaption>&lt;그림-12&gt; 이미지 출처 : 영화 \"HER\" 장면 중 편집</figcaption>\n</figure>\n<h3><strong>4. ChatGPT API를 이용한 서비스 모델</strong></h3>\n<p><strong>1) gpt-turbo-3.5, gpt-4 API 사용법</strong></p>\n<figure>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/3019a0c8a61795b7d181e2a070edadf5/ad059/image13.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 56.32911392405063%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe7UNIP/xAAWEAADAAAAAAAAAAAAAAAAAAABIDH/2gAIAQEAAQUCMX//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAYEAEBAAMAAAAAAAAAAAAAAAABABARIf/aAAgBAQABPyHiCsTbx//aAAwDAQACAAMAAAAQAA//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAaEAEAAwADAAAAAAAAAAAAAAABABEhMYGR/9oACAEBAAE/EHrpsAHNlq2uomoI4ryC1P/Z'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"<그림-13> gpt-turbo-3.5, gpt-4 API 사용법, 이미지 출처 : \nhttps://platform.openai.com/ 스크린샷\" title=\"<그림-13> gpt-turbo-3.5, gpt-4 API 사용법, 이미지 출처 : \nhttps://platform.openai.com/ 스크린샷\" src=\"/static/3019a0c8a61795b7d181e2a070edadf5/828fb/image13.jpg\" srcset=\"/static/3019a0c8a61795b7d181e2a070edadf5/ff44c/image13.jpg 158w,\n/static/3019a0c8a61795b7d181e2a070edadf5/a6688/image13.jpg 315w,\n/static/3019a0c8a61795b7d181e2a070edadf5/828fb/image13.jpg 630w,\n/static/3019a0c8a61795b7d181e2a070edadf5/ad059/image13.jpg 758w\" sizes=\"(max-width: 630px) 100vw, 630px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n</figure>\n<figure>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/3c9e0f33c674903d2b6317509212807c/ad059/image14.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 74.68354430379746%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAIBAwQF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAABl7dRzBg//8QAGhAAAgMBAQAAAAAAAAAAAAAAAQIAAxMQIf/aAAgBAQABBQIKxmb8pcINq43rf//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABoQAQEAAgMAAAAAAAAAAAAAAAEAEBEhMTL/2gAIAQEABj8C4Ly4dt2y3//EABsQAQACAgMAAAAAAAAAAAAAAAEAETFRECFB/9oACAEBAAE/Ibm54ZEacwJYt1Or03UVBhZ//9oADAMBAAIAAwAAABAAD//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABwQAQEBAAIDAQAAAAAAAAAAAAERACFBUYGx0f/aAAgBAQABPxCoDHmda/45MKBiPWWUkkrzgp9x+YXlSjJed//Z'); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"<그림-14> gpt-turbo-3.5, gpt-4 API 사용법, 이미지 출처 : \nhttps://platform.openai.com/ 스크린샷\" title=\"<그림-14> gpt-turbo-3.5, gpt-4 API 사용법, 이미지 출처 : \nhttps://platform.openai.com/ 스크린샷\" src=\"/static/3c9e0f33c674903d2b6317509212807c/828fb/image14.jpg\" srcset=\"/static/3c9e0f33c674903d2b6317509212807c/ff44c/image14.jpg 158w,\n/static/3c9e0f33c674903d2b6317509212807c/a6688/image14.jpg 315w,\n/static/3c9e0f33c674903d2b6317509212807c/828fb/image14.jpg 630w,\n/static/3c9e0f33c674903d2b6317509212807c/ad059/image14.jpg 758w\" sizes=\"(max-width: 630px) 100vw, 630px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n</figure>  \n<p><a href=\"https://platform.openai.com/\">https://platform.openai.com/</a> 이 링크로 들어가셔서 회원가입하고 API 발급받으시면 됩니다.</p>\n<ul>\n<li>콘솔에서 openai 패키지 설치하여 사용</li>\n</ul>\n<p>-> pip install openai</p>\n<ul>\n<li>API 사용한 간단한 예시코드</li>\n</ul>\n<figure>\n<span class=\"gatsby-resp-image-wrapper\" style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; \">\n      <a class=\"gatsby-resp-image-link\" href=\"/static/2f97ee12e6364cf2c77b46119ca6134a/4dfa3/image15.jpg\" style=\"display: block\" target=\"_blank\" rel=\"noopener\">\n    <span class=\"gatsby-resp-image-background-image\" style=\"padding-bottom: 47.46835443037975%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAEDBAX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAFbo9MZQP/EABkQAAIDAQAAAAAAAAAAAAAAAAACAQMRMv/aAAgBAQABBQJdK7JUhtgTg//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABoQAAICAwAAAAAAAAAAAAAAAAABEDEzQYH/2gAIAQEABj8C0Y1wqFH/xAAbEAEBAQACAwAAAAAAAAAAAAABEQAQQXGRof/aAAgBAQABPyG1QXmaGQO1Gew/Zx8+N//aAAwDAQACAAMAAAAQYA//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAdEAACAgIDAQAAAAAAAAAAAAAAAREhMWFBcaHR/9oACAEBAAE/EEY3Jau3OxAhrc2e8la+Yv6DyuzyzA//2Q=='); background-size: cover; display: block;\"></span>\n  <img class=\"gatsby-resp-image-image\" alt=\"<그림-15> API 사용한 간단한 예시코드, 이미지 출처 : JUSTA 작성\" title=\"<그림-15> API 사용한 간단한 예시코드, 이미지 출처 : JUSTA 작성\" src=\"/static/2f97ee12e6364cf2c77b46119ca6134a/828fb/image15.jpg\" srcset=\"/static/2f97ee12e6364cf2c77b46119ca6134a/ff44c/image15.jpg 158w,\n/static/2f97ee12e6364cf2c77b46119ca6134a/a6688/image15.jpg 315w,\n/static/2f97ee12e6364cf2c77b46119ca6134a/828fb/image15.jpg 630w,\n/static/2f97ee12e6364cf2c77b46119ca6134a/4dfa3/image15.jpg 792w\" sizes=\"(max-width: 630px) 100vw, 630px\" style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\" loading=\"lazy\" decoding=\"async\">\n  </a>\n    </span>\n<figcaption>&lt;그림-15&gt; API 사용한 간단한 예시코드, 출처 : JUSTA 작성 </figcaption>\n</figure>\n<p><strong>2) API를 이용한 응용서비스</strong></p>\n<ol>\n<li>PDF화일을 분석요약하고 질문에 대답</li>\n</ol>\n<p><a href=\"https://www.chatpdf.com/\">https://www.chatpdf.com/</a>\n2. Excel화일을 분석요약하고 질문에 대답<br>\n<a href=\"https://chatexcel.com/en\">https://chatexcel.com/en</a>\n3. chatGPT동화생성 - 미드저니 삽화생성 - ebook제작툴<br>\n<a href=\"https://www.youtube.com/watch?v=-79WCOE4Q28\">https://www.youtube.com/watch?v=-79WCOE4Q28</a>\n4. chatGPT로 영어공부<br>\n<a href=\"https://www.youtube.com/watch?v=HLxlKtEAL5U\">https://www.youtube.com/watch?v=HLxlKtEAL5U</a>\n5. chatGPT를 이용한 NPC 캐릭터 및 자유대화 모델<br>\n<a href=\"https://www.youtube.com/watch?v=UVNZ3_FwqJE\">https://www.youtube.com/watch?v=UVNZ3_FwqJE</a>\n<a href=\"https://youtu.be/U4W2rGH9oWs\">https://youtu.be/U4W2rGH9oWs</a>  ChatGPT NPC coaches me talking to people at a party in VR</p>\n<p>이상 세미나 내용 중 언론 분야에 특화된 내용을 제외한 부분을 정리해 보았습니다.</p>\n<p>인공지능 분야는 다 그렇지만, 특히 LLM은 요즘 하루가 다르게 기술이 발전하고 있습니다. 작년에 Stable Diffusion이 엄청 핫했던 것처럼요.</p>\n<p>이 글을 정리하는 중에도 LLM의 할루시네이션을 줄이는 방법이나 개별 레이어의 파라미터값이 의미하는 바를 추적하여 개별튜닝이 가능한 기법 등 신기술들이 튀어나오고 있습니다.</p>\n<p>틈나는대로 시리즈 같은 느낌적 느낌으로 후속 글을 계속 작성해 보겠습니다.</p>\n<p>감사합니다.</p>","frontmatter":{"title":"자연어처리(NLP) 분야 인공지능 발전과 전망 (feat. 데이터저널리즘코리아)","category":"blog","date":"2023.06.20.","description":"자연어처리(NLP) 분야 인공지능 발전과 전망을 지난 5월 진행되었던 데이터저널리즘코리아 세미나 내용을 바탕으로 설명합니다.","postauthor":"Justa"}},"previous":{"fields":{"slug":"/2023-06-02-FP/"},"frontmatter":{"title":"기능점수(Function Point) 기본 개념과 산정방식"}},"next":{"fields":{"slug":"/2023-08-31-Advice-for-Project-Manager/"},"frontmatter":{"title":"서비스 기획자의 성장을 돕는 역량 강화 팁; 성공을 이끄는 비밀 노하우"}}},"pageContext":{"id":"affe0908-debc-569e-bc41-68a6812dbcef","previousPostId":"5183ba40-f213-5b51-9bb3-5a8ed836ba7f","nextPostId":"7fcdf1c5-fc49-5fa7-a6f6-7d5980138ae5"}},"staticQueryHashes":["2841359383"]}