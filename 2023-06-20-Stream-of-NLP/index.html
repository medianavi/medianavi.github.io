<!DOCTYPE html><html lang="ko"><head><meta charSet="utf-8"/><meta http-equiv="x-ua-compatible" content="ie=edge"/><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"/><meta name="generator" content="Gatsby 4.25.9"/><meta name="description" content="자연어처리(NLP) 분야 인공지능 발전과 전망을 지난 5월 진행되었던 데이터저널리즘코리아 세미나 내용을 바탕으로 설명합니다." data-gatsby-head="true"/><meta property="og:title" content="자연어처리(NLP) 분야 인공지능 발전과 전망 (feat. 데이터저널리즘코리아)" data-gatsby-head="true"/><meta property="og:description" content="자연어처리(NLP) 분야 인공지능 발전과 전망을 지난 5월 진행되었던 데이터저널리즘코리아 세미나 내용을 바탕으로 설명합니다." data-gatsby-head="true"/><meta property="og:type" content="website" data-gatsby-head="true"/><meta name="twitter:card" content="summary" data-gatsby-head="true"/><meta name="twitter:creator" content="" data-gatsby-head="true"/><meta name="twitter:title" content="자연어처리(NLP) 분야 인공지능 발전과 전망 (feat. 데이터저널리즘코리아)" data-gatsby-head="true"/><meta name="twitter:description" content="자연어처리(NLP) 분야 인공지능 발전과 전망을 지난 5월 진행되었던 데이터저널리즘코리아 세미나 내용을 바탕으로 설명합니다." data-gatsby-head="true"/><style data-href="/styles.6d4a2b068fe0b7cfb545.css" data-identity="gatsby-global-css">@import url(https://cdn.jsdelivr.net/gh/orioncactus/pretendard/dist/web/static/pretendard-dynamic-subset.css);
/*! normalize.css v8.0.1 | MIT License | github.com/necolas/normalize.css */html{-webkit-text-size-adjust:100%;line-height:1.15}body{margin:0}main{display:block}h1{font-size:2em;margin:.67em 0}hr{box-sizing:content-box;height:0;overflow:visible}pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent}abbr[title]{border-bottom:none;text-decoration:underline;-webkit-text-decoration:underline dotted;text-decoration:underline dotted}b,strong{font-weight:bolder}code,kbd,samp{font-family:monospace,monospace;font-size:1em}small{font-size:80%}sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}sub{bottom:-.25em}sup{top:-.5em}img{border-style:none}button,input,optgroup,select,textarea{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=button],[type=reset],[type=submit],button{-webkit-appearance:button}[type=button]::-moz-focus-inner,[type=reset]::-moz-focus-inner,[type=submit]::-moz-focus-inner,button::-moz-focus-inner{border-style:none;padding:0}[type=button]:-moz-focusring,[type=reset]:-moz-focusring,[type=submit]:-moz-focusring,button:-moz-focusring{outline:1px dotted ButtonText}fieldset{padding:.35em .75em .625em}legend{box-sizing:border-box;color:inherit;display:table;max-width:100%;padding:0;white-space:normal}progress{vertical-align:baseline}textarea{overflow:auto}[type=checkbox],[type=radio]{box-sizing:border-box;padding:0}[type=number]::-webkit-inner-spin-button,[type=number]::-webkit-outer-spin-button{height:auto}[type=search]{-webkit-appearance:textfield;outline-offset:-2px}[type=search]::-webkit-search-decoration{-webkit-appearance:none}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}details{display:block}summary{display:list-item}[hidden]{display:none}:lang(ko) h1,:lang(ko) h2,:lang(ko) h3,:lang(ko) h4{word-break:keep-all}:root{--maxWidth-none:"none";--maxWidth-xs:20rem;--maxWidth-sm:24rem;--maxWidth-md:28rem;--maxWidth-lg:32rem;--maxWidth-xl:36rem;--maxWidth-2xl:42rem;--maxWidth-3xl:48rem;--maxWidth-4xl:56rem;--maxWidth-full:"100%";--maxWidth-wrapper:var(--maxWidth-2xl);--spacing-px:"1px";--spacing-0:0;--spacing-1:0.25rem;--spacing-2:0.5rem;--spacing-3:0.75rem;--spacing-4:1rem;--spacing-5:1.25rem;--spacing-6:1.5rem;--spacing-8:2rem;--spacing-10:2.5rem;--spacing-12:3rem;--spacing-16:4rem;--spacing-20:5rem;--spacing-24:6rem;--spacing-32:8rem;--fontFamily-sans:Pretendard,system-ui,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,"Helvetica Neue",Arial,"Noto Sans","Apple SD Gothic Neo","Noto Sans KR","Malgun Gothic",sans-serif,"Apple Color Emoji","Segoe UI Emoji","Segoe UI Symbol","Noto Color Emoji";--fontFamily-serif:"Merriweather","Georgia",Cambria,"Times New Roman",Times,serif;--font-body:var(--fontFamily-sans);--font-heading:var(--fontFamily-sans);--fontWeight-normal:400;--fontWeight-medium:500;--fontWeight-semibold:600;--fontWeight-bold:700;--fontWeight-extrabold:800;--fontWeight-black:900;--fontSize-root:16px;--lineHeight-none:1;--lineHeight-tight:1.1;--lineHeight-normal:1.5;--lineHeight-relaxed:1.625;--fontSize-0:0.833rem;--fontSize-1:1rem;--fontSize-2:1.2rem;--fontSize-3:1.44rem;--fontSize-4:1.728rem;--fontSize-5:2.074rem;--fontSize-6:2.488rem;--fontSize-7:2.986rem;--color-primary:#e46b00;--color-text-light:#2e353f;--color-heading:#000;--color-heading-black:#000;--color-accent:#d1dce5;--color-key:#2238ce;--color-base:#ededed;--color-text:#000;--base-margin:30px}*,:after,:before{box-sizing:border-box}html{-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;font-size:var(--fontSize-root);line-height:var(--lineHeight-normal);overflow-y:scroll}body{background-color:var(--color-base);color:var(--color-text);font-family:var(--font-body);font-size:var(--fontSize-1)}footer{padding:var(--spacing-6) var(--spacing-0)}hr{background:var(--color-accent);border:0;height:1px}h1,h2,h3,h4,h5,h6{font-family:var(--font-heading);letter-spacing:-.025em;line-height:var(--lineHeight-tight);margin-bottom:var(--spacing-6);margin-top:var(--spacing-12)}h2,h3,h4,h5,h6{font-weight:var(--fontWeight-bold)}h1,h2,h3,h4,h5,h6{color:var(--color-text)}h1{font-size:var(--fontSize-6);font-weight:var(--fontWeight-black)}h2{font-size:var(--fontSize-5)}h3{font-size:var(--fontSize-4)}h4{font-size:var(--fontSize-3)}h5{font-size:var(--fontSize-2)}h6{font-size:var(--fontSize-1)}h1>a,h2>a,h3>a,h4>a,h5>a,h6>a{color:inherit;text-decoration:none}p{--baseline-multiplier:0.179;--x-height-multiplier:0.35;line-height:var(--lineHeight-relaxed);margin:var(--spacing-0) var(--spacing-0) var(--spacing-8) var(--spacing-0)}ol,p,ul{padding:var(--spacing-0)}ol,ul{list-style-image:none;list-style-position:outside;margin-bottom:var(--spacing-8);margin-left:var(--spacing-4);margin-right:var(--spacing-0)}ol li,ul li{padding-left:var(--spacing-0)}li>p,ol li,ul li{margin-bottom:calc(var(--spacing-8)/2)}li :last-child{margin-bottom:var(--spacing-0)}li>ul{margin-left:var(--spacing-8);margin-top:calc(var(--spacing-8)/2)}blockquote{border-left:var(--spacing-1) solid var(--color-key);color:var(--color-text-light);font-size:var(--fontSize-2);font-style:italic;margin-bottom:var(--spacing-8);margin-left:calc(var(--spacing-6)*-1);margin-right:var(--spacing-8);padding:var(--spacing-0) var(--spacing-0) var(--spacing-0) var(--spacing-6)}blockquote>:last-child{margin-bottom:var(--spacing-0)}blockquote>ol,blockquote>ul{list-style-position:inside}table{border-collapse:collapse;border-spacing:.25rem;margin-bottom:var(--spacing-8);width:100%}table thead tr th{border-bottom:1px solid var(--color-accent)}figcaption{font-size:.9em}a{color:var(--color-primary)}a:focus,a:hover{text-decoration:none}.global-wrapper{margin:var(--spacing-0) auto;max-width:var(--maxWidth-wrapper);padding:var(--spacing-10) var(--spacing-5)}.global-wrapper[data-is-root-path=true] .bio{margin-bottom:var(--spacing-20)}.global-header{display:flex;justify-content:space-between;margin-bottom:var(--spacing-12)}.header--menu{display:flex;margin-bottom:0}.header--menu li{color:var(--color-text);font-size:var(--fontSize-2);font-weight:900;letter-spacing:.18rem;line-height:var(--base-margin);list-style:none;margin-left:2rem;text-transform:uppercase}.header--menu a{color:var(--color-text);text-decoration:none}.header--menu a.active{color:var(--color-key)}.main-heading{font-size:var(--fontSize-7);margin:0}.post-list-item{margin-bottom:var(--spacing-8);margin-top:var(--spacing-8)}.post-list-item p{margin-bottom:var(--spacing-0)}.post-list-item h2{color:var(--color-key);font-size:var(--fontSize-4);margin-bottom:var(--spacing-2);margin-top:var(--spacing-0)}.post-list-item header{margin-bottom:var(--spacing-4)}.header-link-home{font-family:var(--font-heading);font-size:var(--fontSize-2);font-weight:var(--fontWeight-bold);text-decoration:none}.bio{display:flex;margin-bottom:var(--spacing-16)}.bio p,.bio-avatar{margin-bottom:var(--spacing-0)}.bio-avatar{border-radius:100%;margin-right:var(--spacing-4);min-width:50px}.blog-post header h1{margin:var(--spacing-0) var(--spacing-0) var(--spacing-4) var(--spacing-0)}.blog-post header p{font-family:var(--font-heading);font-size:var(--fontSize-2)}.blog-post-nav ul{margin:var(--spacing-0)}.gatsby-highlight{margin-bottom:var(--spacing-8)}.header--logo{align-items:center;display:flex;font-size:var(--fontSize-2);font-weight:var(--fontWeight-black);justify-items:center;text-decoration:none}.header--logo--text{color:var(--color-key);letter-spacing:.18rem;line-height:var(--base-margin);margin-left:var(--spacing-2);text-transform:uppercase}.svg_logo{height:var(--base-margin)}.svg_logo_path{fill:var(--color-key)}.copyright{font-size:12px;font-weight:200;letter-spacing:.2em;text-align:center;text-transform:uppercase}.bio{align-items:center}.blog-post img{max-width:100%}.blog-post table td,.blog-post table th{border:1px solid #777;padding:.5em}.responsive-iframe{overflow:hidden;padding-top:56.25%;position:relative;width:100%}.responsive-iframe iframe{bottom:0;height:100%;left:0;position:absolute;right:0;top:0;width:100%}@media(max-width:42rem){:root{--base-margin:16px}blockquote{margin-left:var(--spacing-0);padding:var(--spacing-0) var(--spacing-0) var(--spacing-0) var(--spacing-4)}ol,ul{list-style-position:inside}}@media(prefers-color-scheme:dark){:root{--color-base:#1e1c22;--color-text:#eee;--color-key:#1289ff;--color-text-light:#a4a4a4}}code[class*=language-],pre[class*=language-]{word-wrap:normal;background:none;color:#000;font-family:Consolas,Monaco,Andale Mono,Ubuntu Mono,monospace;font-size:1em;-webkit-hyphens:none;hyphens:none;line-height:1.5;tab-size:4;text-align:left;text-shadow:0 1px #fff;white-space:pre;word-break:normal;word-spacing:normal}code[class*=language-] ::selection,code[class*=language-]::selection,pre[class*=language-] ::selection,pre[class*=language-]::selection{background:#b3d4fc;text-shadow:none}@media print{code[class*=language-],pre[class*=language-]{text-shadow:none}}pre[class*=language-]{margin:.5em 0;overflow:auto;padding:1em}:not(pre)>code[class*=language-],pre[class*=language-]{background:#f5f2f0}:not(pre)>code[class*=language-]{border-radius:.3em;padding:.1em;white-space:normal}.token.cdata,.token.comment,.token.doctype,.token.prolog{color:#708090}.token.punctuation{color:#999}.token.namespace{opacity:.7}.token.boolean,.token.constant,.token.deleted,.token.number,.token.property,.token.symbol,.token.tag{color:#905}.token.attr-name,.token.builtin,.token.char,.token.inserted,.token.selector,.token.string{color:#690}.language-css .token.string,.style .token.string,.token.entity,.token.operator,.token.url{background:hsla(0,0%,100%,.5);color:#9a6e3a}.token.atrule,.token.attr-value,.token.keyword{color:#07a}.token.class-name,.token.function{color:#dd4a68}.token.important,.token.regex,.token.variable{color:#e90}.token.bold,.token.important{font-weight:700}.token.italic{font-style:italic}.token.entity{cursor:help}</style><title data-gatsby-head="true">자연어처리(NLP) 분야 인공지능 발전과 전망 (feat. 데이터저널리즘코리아) | MediaNavi 미디어나비 Blog</title><script async="" src="https://www.googletagmanager.com/gtag/js?id=G-144HB93NR5"></script><script>
    window.GATSBY_GTAG_PLUGIN_GA_TRACKING_ID = (
      'G-144HB93NR5'
    );
    window.GATSBY_GTAG_PLUGIN_ANONYMIZE = false;

    var options = {
      send_page_view: false
    };
    if (false) {
      options.anonymize_ip = true;
    }

    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    window.gtag = gtag;
    gtag('js', new Date());
    gtag('config', 'G-144HB93NR5', options);
  </script><style>.gatsby-image-wrapper{position:relative;overflow:hidden}.gatsby-image-wrapper picture.object-fit-polyfill{position:static!important}.gatsby-image-wrapper img{bottom:0;height:100%;left:0;margin:0;max-width:none;padding:0;position:absolute;right:0;top:0;width:100%;object-fit:cover}.gatsby-image-wrapper [data-main-image]{opacity:0;transform:translateZ(0);transition:opacity .25s linear;will-change:opacity}.gatsby-image-wrapper-constrained{display:inline-block;vertical-align:top}</style><noscript><style>.gatsby-image-wrapper noscript [data-main-image]{opacity:1!important}.gatsby-image-wrapper [data-placeholder-image]{opacity:0!important}</style></noscript><script type="module">const e="undefined"!=typeof HTMLImageElement&&"loading"in HTMLImageElement.prototype;e&&document.body.addEventListener("load",(function(e){const t=e.target;if(void 0===t.dataset.mainImage)return;if(void 0===t.dataset.gatsbyImageSsr)return;let a=null,n=t;for(;null===a&&n;)void 0!==n.parentNode.dataset.gatsbyImageWrapper&&(a=n.parentNode),n=n.parentNode;const o=a.querySelector("[data-placeholder-image]"),r=new Image;r.src=t.currentSrc,r.decode().catch((()=>{})).then((()=>{t.style.opacity=1,o&&(o.style.opacity=0,o.style.transition="opacity 500ms linear")}))}),!0);</script><link rel="alternate" type="application/rss+xml" title="MediaNavi blog" href="/rss.xml"/><link rel="icon" href="/favicon-32x32.png?v=6bfe33411e9e143f9e2c946e9de05911" type="image/png"/><link rel="manifest" href="/manifest.webmanifest" crossorigin="anonymous"/><link rel="apple-touch-icon" sizes="48x48" href="/icons/icon-48x48.png?v=6bfe33411e9e143f9e2c946e9de05911"/><link rel="apple-touch-icon" sizes="72x72" href="/icons/icon-72x72.png?v=6bfe33411e9e143f9e2c946e9de05911"/><link rel="apple-touch-icon" sizes="96x96" href="/icons/icon-96x96.png?v=6bfe33411e9e143f9e2c946e9de05911"/><link rel="apple-touch-icon" sizes="144x144" href="/icons/icon-144x144.png?v=6bfe33411e9e143f9e2c946e9de05911"/><link rel="apple-touch-icon" sizes="192x192" href="/icons/icon-192x192.png?v=6bfe33411e9e143f9e2c946e9de05911"/><link rel="apple-touch-icon" sizes="256x256" href="/icons/icon-256x256.png?v=6bfe33411e9e143f9e2c946e9de05911"/><link rel="apple-touch-icon" sizes="384x384" href="/icons/icon-384x384.png?v=6bfe33411e9e143f9e2c946e9de05911"/><link rel="apple-touch-icon" sizes="512x512" href="/icons/icon-512x512.png?v=6bfe33411e9e143f9e2c946e9de05911"/></head><body><div id="___gatsby"><div style="outline:none" tabindex="-1" id="gatsby-focus-wrapper"><div class="global-wrapper" data-is-root-path="false"><header class="global-header"><a class="header--logo" href="/"><svg xmlns="http://www.w3.org/2000/svg" role="img" class="svg_logo" preserveAspectRatio="none" viewBox="0 0 205.71 90"><title>미디어나비 로고</title><path class="svg_logo_path" d="M202.22,0H176.37a9,9,0,0,0-7.52,5.12l-19,43.4-19-43.4A9,9,0,0,0,123.35,0H97.4a9,9,0,0,0-7.52,5.12L79.15,29.64,75.29,5.12A6.32,6.32,0,0,0,69.2,0H42.88a9,9,0,0,0-7.52,5.12L.46,84.88C-.78,87.71.58,90,3.5,90H29.34a9,9,0,0,0,7.52-5.12L47.59,60.36l3.86,24.52A6.33,6.33,0,0,0,57.54,90H83.86a9,9,0,0,0,7.53-5.12l19-43.4,19,43.4A9,9,0,0,0,136.89,90h25.94a9,9,0,0,0,7.52-5.12L205.26,5.12C206.49,2.29,205.13,0,202.22,0ZM51.51,51.4,70.44,8.16,75.23,38.6,56.31,81.84Zm61.73-16.46L125.66,6.56a2.8,2.8,0,0,1,.36.56l21,47.94L134.58,83.44a2.42,2.42,0,0,1-.36-.56Z"></path></svg><span class="header--logo--text">Blog</span></a><ul class="header--menu"><li><a href="/">Posts</a></li><li><a href="/works">Works</a></li></ul></header><main><article class="blog-post" itemscope="" itemType="http://schema.org/Article"><header><h1 itemProp="headline">자연어처리(NLP) 분야 인공지능 발전과 전망 (feat. 데이터저널리즘코리아)</h1><p>2023.06.20.</p></header><section itemProp="articleBody"><p>안녕하세요, JUSTA입니다.<br>
이번에 한국언론진흥재단 프로젝트를 했던 인연으로 데이터저널리즘코리아에서 진행하는 5월 세미나에 강사로 발표를 하였답니다.</p>
<figure>
<span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; ">
      <a class="gatsby-resp-image-link" href="/static/e32b5c6298b13edbccc9afd0bf2fc1d0/ad059/image01.jpg" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 116.45569620253164%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAXABQDASIAAhEBAxEB/8QAGAABAQEBAQAAAAAAAAAAAAAAAAIBAwX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAH3JrSgc9Cwf//EABcQAAMBAAAAAAAAAAAAAAAAAAABETD/2gAIAQEAAQUCbhZh/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPwEf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPwEf/8QAGBAAAgMAAAAAAAAAAAAAAAAAAAEwMTL/2gAIAQEABj8Cpsy4P//EABoQAAIDAQEAAAAAAAAAAAAAAAABMUFRECH/2gAIAQEAAT8hc1jDCPBeoc0IQ5Fz/9oADAMBAAIAAwAAABDDxwD/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/EB//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/EB//xAAcEAEBAAMBAAMAAAAAAAAAAAABEQAhMVFBYXH/2gAIAQEAAT8QMAb5EhgSNyXQ19d7igxKWPTErA63lGxZ+OUm8Je3vmS8rPQwk0TP/9k='); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="<그림-1> 데이터저널리즘코리아 세미나 초대장 앞면, 이미지 출처 : 데이터저널리즘코리아 운영진" title="<그림-1> 데이터저널리즘코리아 세미나 초대장 앞면, 이미지 출처 : 데이터저널리즘코리아 운영진" src="/static/e32b5c6298b13edbccc9afd0bf2fc1d0/828fb/image01.jpg" srcset="/static/e32b5c6298b13edbccc9afd0bf2fc1d0/ff44c/image01.jpg 158w,
/static/e32b5c6298b13edbccc9afd0bf2fc1d0/a6688/image01.jpg 315w,
/static/e32b5c6298b13edbccc9afd0bf2fc1d0/828fb/image01.jpg 630w,
/static/e32b5c6298b13edbccc9afd0bf2fc1d0/ad059/image01.jpg 758w" sizes="(max-width: 630px) 100vw, 630px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span>
<figcaption>&lt;그림-1&gt; 데이터저널리즘코리아 세미나 초대장 앞면, 이미지 출처 : 데이터저널리즘코리아 운영진</figcaption>
</figure>  
<figure>
<span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; ">
      <a class="gatsby-resp-image-link" href="/static/1cde331fb7c7e922b9a30ba5e6cbcc3a/ad059/image02.jpg" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 109.49367088607596%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAWABQDASIAAhEBAxEB/8QAGQABAAMBAQAAAAAAAAAAAAAAAAEDBQQG/8QAFQEBAQAAAAAAAAAAAAAAAAAAAAH/2gAMAwEAAhADEAAAAdyfPbEdYqqwJB//xAAbEAABBAMAAAAAAAAAAAAAAAABAAIEEAMRI//aAAgBAQABBQK5Ja3JHHBEDdf/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AR//xAAZEAACAwEAAAAAAAAAAAAAAAAQEQABAjL/2gAIAQEABj8COnTmEOaP/8QAHhABAAIBBAMAAAAAAAAAAAAAAQARIRAxQVFhgZH/2gAIAQEAAT8hd+PsA60JrCvqFkYqVEpVfJCgwVLn/9oADAMBAAIAAwAAABD7CAD/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/EB//xAAWEQEBAQAAAAAAAAAAAAAAAAABESD/2gAIAQIBAT8QG4//xAAdEAEBAAICAwEAAAAAAAAAAAABEQAhMVEQYZHB/9oACAEBAAE/ECc6+McWPt8FQXLd3xPeVW1Y9ir+4QSudqJBcYQAGgNGRn//2Q=='); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="<그림-2> 데이터저널리즘코리아 세미나 초대장 뒷면, 이미지 출처 : 데이터저널리즘코리아 운영진" title="<그림-2> 데이터저널리즘코리아 세미나 초대장 뒷면, 이미지 출처 : 데이터저널리즘코리아 운영진" src="/static/1cde331fb7c7e922b9a30ba5e6cbcc3a/828fb/image02.jpg" srcset="/static/1cde331fb7c7e922b9a30ba5e6cbcc3a/ff44c/image02.jpg 158w,
/static/1cde331fb7c7e922b9a30ba5e6cbcc3a/a6688/image02.jpg 315w,
/static/1cde331fb7c7e922b9a30ba5e6cbcc3a/828fb/image02.jpg 630w,
/static/1cde331fb7c7e922b9a30ba5e6cbcc3a/ad059/image02.jpg 758w" sizes="(max-width: 630px) 100vw, 630px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span>
<figcaption>&lt;그림-2&gt; 데이터저널리즘코리아 세미나 초대장 뒷면, 이미지 출처 : 데이터저널리즘코리아 운영진</figcaption>
</figure>  
<p>발표내용은 한국언론진흥재단이 만든 kpf-BERT 관련 비하인드 스토리와 응용 서비스 개발이지만 아시다시피 요즘 자연어처리에서는 ChatGPT가 모두 집어 삼킨 상황이잖아요?<br>
그래서 실제로 발표의 초점은 GPT와 대규모언어모델(LLM)의 흐름과 전망으로 잡아보았습니다.</p>
<p>우리 블로그에도 발 표내용을 대략적으로 정리하는 글을 써보려 하니 모쪼록 도움이 되었으면 좋겠습니다.</p>
<p>참고로 그사이에도 많은 기술들이 발표되고 있네요.
관련해서 신기술들 계속 따라갈 수 있게 자주 발행할 수 있도록 하겠습니다.</p>
<h3><strong>1. 한국언론진흥재단 kpf-BERT 복습</strong></h3>
<p><strong>1) kpf-BERT 제작</strong></p>
<figure>
<span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; ">
      <a class="gatsby-resp-image-link" href="/static/a46f088dd4e07e886c443cb20ffa4f9a/d4b53/image03.jpg" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 46.835443037974684%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe5WiKP/xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAEFAl//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAYEAADAQEAAAAAAAAAAAAAAAAAARAhQf/aAAgBAQABPyEeTg5//9oADAMBAAIAAwAAABDjz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABsQAAEEAwAAAAAAAAAAAAAAAAEAEBExIVGx/9oACAEBAAE/EDkAwLVEbYdKwb//2Q=='); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="<그림-3> kpf-BERT 성능 측정 결과 비교표, 이미지 출처 : 한국언론진흥재단" title="<그림-3> kpf-BERT 성능 측정 결과 비교표, 이미지 출처 : 한국언론진흥재단" src="/static/a46f088dd4e07e886c443cb20ffa4f9a/828fb/image03.jpg" srcset="/static/a46f088dd4e07e886c443cb20ffa4f9a/ff44c/image03.jpg 158w,
/static/a46f088dd4e07e886c443cb20ffa4f9a/a6688/image03.jpg 315w,
/static/a46f088dd4e07e886c443cb20ffa4f9a/828fb/image03.jpg 630w,
/static/a46f088dd4e07e886c443cb20ffa4f9a/d4b53/image03.jpg 853w" sizes="(max-width: 630px) 100vw, 630px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span>
<figcaption>&lt;그림-3&gt; kpf-BERT 성능 측정 결과 비교표, 이미지 출처 : 한국언론진흥재단</figcaption>
</figure>  
<p>이런 성능 좋은 BERT를 한국언론진흥재단에서 만들었었죠.
그 당시 최신의 기술(Distilbert 등)이 가미되고, 정제된 신문기사 데이터가 학습되어 좀 더 좋은 성능이 나왔을 것으로 생각됩니다.</p>
<p>관심 있으시면 아래 링크로…<br>
<a href="https://github.com/KPFBERT/kpfbert">https://github.com/KPFBERT/kpfbert</a> 깃헙 모델저장 링크<br>
<a href="https://youtu.be/Pj6563CAnKs">https://youtu.be/Pj6563CAnKs</a> BERT란 무엇인가</p>
<p><strong>2) 응용 서비스 예제</strong>
응용 서비스에 활용할 수 있는 예제소스도 아래와 같이 공개되어 있습니다.<br>
<a href="https://github.com/KPFBERT/kpfSBERT">https://github.com/KPFBERT/kpfSBERT</a> 문장임베딩 BERT<br>
<a href="https://github.com/KPFBERT/kpfSBERT_Clustering">https://github.com/KPFBERT/kpfSBERT_Clustering</a>   클러스터링<br>
<a href="https://github.com/KPFBERT/kpfbertsum">https://github.com/KPFBERT/kpfbertsum</a> 텍스트 요약 예제</p>
<p>여기까지가 벌써 2년 전 일이네요.
요즘 인공지능의 발전속도는 자고 일어나면 세상이 변해있는 수준이죠.<br>
2년 전이면… 이제는 유물이 된 것 같은 느낌이네요.</p>
<p>서론에 말씀드린 것처럼 요즘 대세는 ChatGPT이죠. 그래서 이제 GPT, LLM, 그 틈새 기술과 전망에 대해 이야기 해보죠.</p>
<figure>
<span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 189px; ">
      <a class="gatsby-resp-image-link" href="/static/deb828ec61c64740886cbcd79d0b3b05/bd682/image04.jpg" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 100.63291139240506%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGQABAAMBAQAAAAAAAAAAAAAAAAIDBAEF/8QAFgEBAQEAAAAAAAAAAAAAAAAAAQAC/9oADAMBAAIQAxAAAAHNKy/F5ja0RtF4C//EABsQAAICAwEAAAAAAAAAAAAAAAECABIDERMy/9oACAEBAAEFAtEBUaPYM2TRRr4+lYECN5ljP//EABYRAQEBAAAAAAAAAAAAAAAAAAERIP/aAAgBAwEBPwFJj//EABcRAAMBAAAAAAAAAAAAAAAAAAACEBH/2gAIAQIBAT8BQy//xAAgEAABAgUFAAAAAAAAAAAAAAABADECAxESURAhIkFC/9oACAEBAAY/Au0AYnZULoQS9yqwvjC5S7jkhXByjT0+n//EABsQAQADAQEBAQAAAAAAAAAAAAEAETEhQVGB/9oACAEBAAE/IVlGvqFhFNF+lxOVBzZxh35cRcJr1Eqvt7Ys4wNt6Rl//9oADAMBAAIAAwAAABB0KP3/xAAXEQADAQAAAAAAAAAAAAAAAAAAASEQ/9oACAEDAQE/EEwmXf/EABcRAQADAAAAAAAAAAAAAAAAAAEAEBH/2gAIAQIBAT8QCmpZn//EABsQAQACAwEBAAAAAAAAAAAAAAEAESExQWFx/9oACAEBAAE/ELgztOhjAC7xQHt8JmLaBVKgq04adzJVTTyGyuRpcc7h54aPkOVsXnXyJTKb1ZZuy3eD5P/Z'); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="<그림-4> kpf-BERT 토닥토닥..., 이미지 출처 : https://m.animalplanet.co.kr/contents/?artNo=8657" title="<그림-4> kpf-BERT 토닥토닥..., 이미지 출처 : https://m.animalplanet.co.kr/contents/?artNo=8657" src="/static/deb828ec61c64740886cbcd79d0b3b05/bd682/image04.jpg" srcset="/static/deb828ec61c64740886cbcd79d0b3b05/ff44c/image04.jpg 158w,
/static/deb828ec61c64740886cbcd79d0b3b05/bd682/image04.jpg 189w" sizes="(max-width: 189px) 100vw, 189px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span>
<figcaption> &lt;그림-4&gt; kpf-BERT 토닥토닥, 이미지 출처 : https://m.animalplanet.co.kr/contents/?artNo=8657</figcaption>
</figure>
<h3><strong>2. LLM - ChatGPT 공주와 일곱 난쟁이들</strong></h3>
<figure>
<span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; ">
      <a class="gatsby-resp-image-link" href="/static/db3d25c3f9ca58632183a087ae28c774/3c4de/image05.jpg" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAUABQDASIAAhEBAxEB/8QAGAABAAMBAAAAAAAAAAAAAAAAAAMEBQH/xAAYAQACAwAAAAAAAAAAAAAAAAAAAQIDBP/aAAwDAQACEAMQAAAB1eVo8711RaW4CSlAf//EABwQAAICAgMAAAAAAAAAAAAAAAECAAMRIRMiMv/aAAgBAQABBQJ7IlmKxsHT+ZUeuBOFMhAs/8QAFxEAAwEAAAAAAAAAAAAAAAAAAAEREP/aAAgBAwEBPwGMm//EABoRAAEFAQAAAAAAAAAAAAAAAAABAhAREiH/2gAIAQIBAT8B0I7hUf/EABsQAAMAAgMAAAAAAAAAAAAAAAABESExAhAS/9oACAEBAAY/AnxVE3eoeVYZTNGjB//EABwQAQACAwEBAQAAAAAAAAAAAAEAESExUYFhcf/aAAgBAQABPyG5Cnp2HsL2Kh7DZSsuY92mY+6bizaHyKJ2fsKoUfs//9oADAMBAAIAAwAAABDf50P/xAAXEQADAQAAAAAAAAAAAAAAAAAAAREQ/9oACAEDAQE/ECorz//EABkRAQEAAwEAAAAAAAAAAAAAAAEAESExwf/aAAgBAgEBPxDLa98swWQ9IAv/xAAbEAEBAQEBAQEBAAAAAAAAAAABESEAMUFRwf/aAAgBAQABPxCIVpjseb15bbhmM+cIIgKUj3xEBW0vu+dYFQiEgPo8pqZ66/mzlyZ9UdeEWrX9691Li97/2Q=='); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="<그림-5> ChatGPT 공주와 일곱 난쟁이들, 이미지 출처 : 디즈니 애니메이션 백설공주와 일곱 난쟁이 중 편집" title="<그림-5> ChatGPT 공주와 일곱 난쟁이들, 이미지 출처 : 디즈니 애니메이션 백설공주와 일곱 난쟁이 중 편집" src="/static/db3d25c3f9ca58632183a087ae28c774/828fb/image05.jpg" srcset="/static/db3d25c3f9ca58632183a087ae28c774/ff44c/image05.jpg 158w,
/static/db3d25c3f9ca58632183a087ae28c774/a6688/image05.jpg 315w,
/static/db3d25c3f9ca58632183a087ae28c774/828fb/image05.jpg 630w,
/static/db3d25c3f9ca58632183a087ae28c774/3c4de/image05.jpg 756w" sizes="(max-width: 630px) 100vw, 630px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span>
<figcaption> &lt;그림-5&gt; ChartGPT 백설공주와 일곱난쟁이들, 이미지 출처 : 디즈니 애니메이션 "백설공주와 일곱 난쟁이" 중 편집</figcaption>
</figure>  
<p>자, 요즘 대규모언어모델의 분위기를 어떻게 표현해 볼 수 있을까 하다가 선택한 그림입니다. 백설공주와 일곱 난쟁이들.
딱 맞는 상황은 아니겠지만, 어쨌든 ChatGPT가 1-TOP으로 시장을 평정했고, 그 와중에 소규모 로컬 LLM들이 우후죽순 생겨나고 있지요.</p>
<p>아래 막대 그래프는 최근에 나와있는 로컬 LLM 모델들을 비교해 놓았길래, 어떤 모델들이 있는지 보기 편해서 가져와 봤습니다. 7개가 훨씬 넘네요.ㅎㅎ</p>
<figure>
<span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; ">
      <a class="gatsby-resp-image-link" href="/static/b6367303d5158fc775e78c78f0d8c4bb/ad059/image06.jpg" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 191.13924050632912%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAmABQDASIAAhEBAxEB/8QAGAABAQEBAQAAAAAAAAAAAAAAAAUEAgP/xAAWAQEBAQAAAAAAAAAAAAAAAAACAQD/2gAMAwEAAhADEAAAAbeHbgIoulXnLqS1rIl4zEWwU//EAB0QAAICAgMBAAAAAAAAAAAAAAECAzIAIRAREyL/2gAIAQEAAQUCkqrNidlZKKdDQkp9HiWik+mPWNCrZ//EABoRAAICAwAAAAAAAAAAAAAAAAEQIfACEUH/2gAIAQMBAT8By3xWygIX/8QAGBEBAAMBAAAAAAAAAAAAAAAAARARIEH/2gAIAQIBAT8BVgvhj//EAB0QAAIBBAMAAAAAAAAAAAAAAAABEAIRIUIxMlH/2gAIAQEABj8COpkZtDllKTfPkWNY/8QAIRABAAIBAwQDAAAAAAAAAAAAAQARIRAxoUFRYZHR4fD/2gAIAQEAAT8hVNC0lL4fUQHcziQur2hpLuJIl5WNOFMWF/G2ma7oJxTwZlz/2gAMAwEAAgADAAAAEGcw/AwP/8QAHBEBAAEEAwAAAAAAAAAAAAAAAQAQESFhgeHw/9oACAEDAQE/EEOkL2zM69woSlKf/8QAGREAAwADAAAAAAAAAAAAAAAAAAExIFFx/9oACAECAQE/EFIKGsfcP//EAB4QAQEAAgEFAQAAAAAAAAAAAAERACExEEFRkdGh/9oACAEBAAE/EELAKau/TjktNtvAnzZMjeptxlz8z9zaaDlauM5tinrG5IoSH3DA1LpbC46NC9vPnoE4FM3xjCyi3wOj/9k='); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="<그림-6> LLMs vs. Double Jeopardy, 이미지 출처 : https://www.reddit.com/r/LocalLLaMA/comments/13hd8dt/llm_double_jeopardy_testing_with_new_models/" title="<그림-6> LLMs vs. Double Jeopardy, 이미지 출처 : https://www.reddit.com/r/LocalLLaMA/comments/13hd8dt/llm_double_jeopardy_testing_with_new_models/" src="/static/b6367303d5158fc775e78c78f0d8c4bb/828fb/image06.jpg" srcset="/static/b6367303d5158fc775e78c78f0d8c4bb/ff44c/image06.jpg 158w,
/static/b6367303d5158fc775e78c78f0d8c4bb/a6688/image06.jpg 315w,
/static/b6367303d5158fc775e78c78f0d8c4bb/828fb/image06.jpg 630w,
/static/b6367303d5158fc775e78c78f0d8c4bb/ad059/image06.jpg 758w" sizes="(max-width: 630px) 100vw, 630px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span>
<figcaption>&lt;그림-6&gt; LLMs vs. Double Jeopardy, 이미지 출처 : https://www.reddit.com/r/LocalLLaMA/comments/13hd8dt/llm_double_jeopardy_testing_with_new_models/</figcaption>
</figure>  
<p>그럼 왜 갑자기 언어모델이 인공지능 판에서 메인이 되었을까요?</p>
<p><strong>1) AI와 NLP, 그리고 AGI</strong></p>
<p>최초에 인공지능은 인간과 동등한 수준의 일반인공지능(AGI, Artficial General Intelligence, 강인공지능이라고 불리기도 함)의 구현이 목표였으나, 과거의 기술과 장비로는 불가능함을 깨닫고 각각의 소분류별 쓰임에 따라 발전해오고 있었죠.</p>
<p>비전이나 음성처럼 언어도 NLP(자연어처리)라는 한 분야로서 시작했는데, 성능이 발전할수록, 지금의 ChatGPT에 이르러서는 그 자체로 AGI의 가능성을 보이는 겁니다.</p>
<p>언어를 깊게 이해하면 그 자체가 지능이 될 수 있는것 아닌가하는 가능성을 보여주는 수준에 이른 것이지요.</p>
<p><strong>2) LLM의 눈부신 발전 - 클수록 좋다!</strong></p>
<p>LLM(Large Language Model)은 말 그대로 거대언어모델입니다.
거대한 사이즈와 거대한 학습량을 기반으로 큰 성능향상을 이룬면서 생긴 트랜드이지요.</p>
<p>GPT3를 기점으로 모델 사이즈가 크면 클수록 좋은 성능이 나온다는 흐름이 있었습니다.</p>
<p>이후 학습데이터의 양이 많을수록 좋은 성능이 나온다는 주장도 생겼죠.</p>
<p>하단의 참고 이미지를 보시면 거대한 사이즈의 전쟁이 벌어진 것을 알 수 있습니다.</p>
<figure>
<span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; ">
      <a class="gatsby-resp-image-link" href="/static/469fad12eeb5a85ed46ffea568a96dd2/ad059/image07.jpg" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 56.32911392405063%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAQFAgP/xAAWAQEBAQAAAAAAAAAAAAAAAAACAAH/2gAMAwEAAhADEAAAAX1uGEaxILf/xAAaEAADAQADAAAAAAAAAAAAAAAAAQITAxIh/9oACAEBAAEFAvOzOJpTtZrZtZ//xAAXEQEAAwAAAAAAAAAAAAAAAAAAARFh/9oACAEDAQE/AZxb/8QAFhEAAwAAAAAAAAAAAAAAAAAAARAx/9oACAECAQE/ARV//8QAHBAAAgICAwAAAAAAAAAAAAAAAAExoQIREiEy/9oACAEBAAY/AuKwY9dntE0TRNH/xAAfEAEAAgEDBQAAAAAAAAAAAAABABEhMUGRUWFxscH/2gAIAQEAAT8hc9gb7VG8sr1KWmua6douPylGQHgRt08J/9oADAMBAAIAAwAAABBoH//EABkRAAMAAwAAAAAAAAAAAAAAAAABESFRkf/aAAgBAwEBPxCMQuC0P//EABkRAQACAwAAAAAAAAAAAAAAAAEAETFRof/aAAgBAgEBPxCwlXG+xLbn/8QAHhABAAICAgMBAAAAAAAAAAAAAQARITFBkWFxobH/2gAIAQEAAT8QYzw2lwabuYwOdVuDt7lzcDxu4Oz5lkFsp5DqXhYaofhLZyO3Z8n/2Q=='); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="<그림-7> LANGUAGE MODEL SIZES TO DEC/2022, 이미지 출처 : https://www.reddit.com/r/mlscaling/comments/wizfmm/language_model_sizes_to_aug2022/" title="<그림-7> LANGUAGE MODEL SIZES TO DEC/2022, 이미지 출처 : https://www.reddit.com/r/mlscaling/comments/wizfmm/language_model_sizes_to_aug2022/" src="/static/469fad12eeb5a85ed46ffea568a96dd2/828fb/image07.jpg" srcset="/static/469fad12eeb5a85ed46ffea568a96dd2/ff44c/image07.jpg 158w,
/static/469fad12eeb5a85ed46ffea568a96dd2/a6688/image07.jpg 315w,
/static/469fad12eeb5a85ed46ffea568a96dd2/828fb/image07.jpg 630w,
/static/469fad12eeb5a85ed46ffea568a96dd2/ad059/image07.jpg 758w" sizes="(max-width: 630px) 100vw, 630px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span>
<figcaption>&lt;그림-7&gt; LANGUAGE MODEL SIZES TO DEC/2022, 이미지 출처 : https://www.reddit.com/r/mlscaling/comments/wizfmm/language_model_sizes_to_aug2022/</figcaption>
</figure>  
<p>하지만 크다고 무조건 성능이 좋다는 것은 아닌 것으로 밝혀지며 지각변동이 생깁니다.</p>
<p>OpenAI가 잘 정제된 데이터에 인간의 피드백을 추가해 학습한 ChatGPT라는 월등한 성능의 모델을 내 놓게 되면서 크기경쟁은 일단락 되는데요.</p>
<p>다들 잘 알고 계시리라 생각되어 일단 ChatGPT의 설명은 생략하겠습니다.</p>
<p>하지만 ChatGPT의 등장은 새로운 언어모델 학습의 길을 만들어주게 됩니다.</p>
<p>바로 로컬 LLM의 등장을 가속화하는 계기가 된 것입니다.</p>
<p><strong>3) sLLM의 반격 - 작은 것도 충분히 좋다!</strong></p>
<p>sLLM(Small Large Language Model)이라는 모순적인 용어로도 불리는 로컬LLM모델은 아이러니하게 ChatGPT 덕분에 저렴하게 고성능으로 학습할 수 있게 되었습니다. 바로 ChatGPT에 질문과 답변을 받아내어 학습데이터로 사용하는 것이지요.</p>
<p>이로써 ChatGPT 학습에 사용된 데이터 가공 비용에 비하면 거의 공짜나 다름없는 비용으로 아주 양질의 학습데이터를 방대하게 만들어 쓸 수 있게 된 것이죠.</p>
<figure>
<span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; ">
      <a class="gatsby-resp-image-link" href="/static/30552d82d4e79cc1011ff87e43e5dcf1/ad059/image08.jpg" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 43.67088607594937%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIDBf/EABUBAQEAAAAAAAAAAAAAAAAAAAEA/9oADAMBAAIQAxAAAAHaWiFUkJ//xAAZEAEAAgMAAAAAAAAAAAAAAAABAAIQEjH/2gAIAQEAAQUCbJHaHM//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAYEAACAwAAAAAAAAAAAAAAAAABAhAgIf/aAAgBAQAGPwLFgU//xAAZEAACAwEAAAAAAAAAAAAAAAABEQAhMRD/2gAIAQEAAT8hqCHIb1iMe7V0T//aAAwDAQACAAMAAAAQ6P8A/8QAFxEAAwEAAAAAAAAAAAAAAAAAARARMf/aAAgBAwEBPxA5F//EABYRAQEBAAAAAAAAAAAAAAAAABEAIf/aAAgBAgEBPxA1i//EABwQAAICAgMAAAAAAAAAAAAAAAERADEhQRBRkf/aAAgBAQABPxAkUOzwXfkWB7JA2sTdcDffBuUn/9k='); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="<그림-8> GPT-4 grades LLM output, 이미지 출처 : https://vicuna.lmsys.org/" title="<그림-8> GPT-4 grades LLM output, 이미지 출처 : https://vicuna.lmsys.org/" src="/static/30552d82d4e79cc1011ff87e43e5dcf1/828fb/image08.jpg" srcset="/static/30552d82d4e79cc1011ff87e43e5dcf1/ff44c/image08.jpg 158w,
/static/30552d82d4e79cc1011ff87e43e5dcf1/a6688/image08.jpg 315w,
/static/30552d82d4e79cc1011ff87e43e5dcf1/828fb/image08.jpg 630w,
/static/30552d82d4e79cc1011ff87e43e5dcf1/ad059/image08.jpg 758w" sizes="(max-width: 630px) 100vw, 630px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span>
<figcaption>&lt;그림-8&gt; GPT-4 grades LLM output, 이미지 출처 : https://vicuna.lmsys.org/</figcaption>
</figure>  
<p>위 표를 보면 성능비교의 기준점이 ChatGPT가 되어버렸네요. 너도 나도 모델을 내놓을 때 “ChatGPT 보다 뛰어나다” 또는 “몇% 성능이다” 라고 하는 세상입니다.</p>
<p>로컬LLM이 ChatGPT 대비 성능이 잘 나오는 이유 중엔 ChatGPT가 생성한 데이터를 쓴 영향도 존재하는 것이죠.</p>
<p>물론 성능은 ChatGPT가 여전히 압도적으로 좋습니다만, 로컬모델도 나름대로의 필요성에 의해 만들어지고 있습니다.</p>
<p>앞에서 ChatGPT 공주와 일곱 난쟁이 중에 첫째 난쟁이로 LLaMA를 꼽았습니다.</p>
<p>META(구 페이스북)에서 개발하여 공개(?)당한 로컬LLM모델입니다.</p>
<p>META는 이것을 오픈소스로 공개하기는 했는데, 학술목적으로 waitlist 신청을 받아서 순차적으로 조금씩 공개하고 있었습니다.</p>
<p>그런데, 어떤 유저가 이 모델을 받아서 토랜트로 풀어버립니다.</p>
<p>이로써 강제공개(?)…<br>
※ 하지만 META는 OpenAI(라 쓰고 ClosedAI라고 읽는다!)보다 훨씬 OPEN된 마인드로 기술들을 공개하고 있으니 많이 칭찬해 주세요~</p>
<p>이때부터 sLLM의 꽃이 피기 시작했다고 할 만한 상황으로 발전하였고, 제가 난장이 중 첫 번째의 영광을 주었습니다.^^</p>
<p>여기에 채팅식 문답가공 파인튜닝과 인스트럭션 튜닝을 거친 Alpaca나 Vicuna 등의 모델들이 나오며 sLLM모델의 기술과 기법들이 빠르게 발전하였습니다.</p>
<h3><strong>3. 로컬 LLM 모델의 가능성과 활용</strong></h3>
<p>그러면 강력한 성능의 ChatGPT를 API로 이용하면 될텐데, 왜 로컬언어모델을 쓸까요?</p>
<p>ChatGPT의 일반적인 강력한 성능은 너무나 좋지만 모든경우에 적용하기는 부적절한 경우가 존재합니다.</p>
<p>의료나 법률처럼 일반적인 지식은 필요없고, 특수한 도메인에 국한된 서비스만 필요하다면 ChatGPT는 너무 거대할 수도 있죠.</p>
<p>마치 아래 이미지와 같이 닭 잡는데 소 잡는 칼을 쓰는 것처럼요.</p>
<figure>
<span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; ">
      <a class="gatsby-resp-image-link" href="/static/8b9974b0ab33ef20b6ae7ef594236548/ad059/image09.jpg" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 95.56962025316456%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAATABQDASIAAhEBAxEB/8QAGAABAQEBAQAAAAAAAAAAAAAAAAMEAgX/xAAVAQEBAAAAAAAAAAAAAAAAAAABAP/aAAwDAQACEAMQAAAB860qT0yq06gbAf/EABsQAAICAwEAAAAAAAAAAAAAAAECAxEAEiEi/9oACAEBAAEFArohheRqZCYyo1kbF4VO7yeG/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAwEBPwEf/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPwEf/8QAGxAAAgMAAwAAAAAAAAAAAAAAAAECESEQEpH/2gAIAQEABj8CwrjqWtLSfhhBS1FRdI//xAAZEAEBAQEBAQAAAAAAAAAAAAABEQAxQVH/2gAIAQEAAT8hvRTib3cQHy6S+4vzdBj8xLVMjpRKZttCy7//2gAMAwEAAgADAAAAEOjHvP/EABcRAQADAAAAAAAAAAAAAAAAAAEAEDH/2gAIAQMBAT8QLMn/xAAYEQEBAAMAAAAAAAAAAAAAAAABABARIf/aAAgBAgEBPxDlswhf/8QAGxABAAMBAQEBAAAAAAAAAAAAAQARITFBcVH/2gAIAQEAAT8QtRBd+272Xv3RPoRVUMCj1bfwyb9voDwPSF5uOskuOy8mlsQoe7kx+yhdZ//Z'); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="<그림-09> 닭 잡는데 소 잡는 칼을 쓰는 꼴을 설명하는 이미지, 이미지 출처 : https://twitter.com/dev_humor/status/1081973719801712640" title="<그림-09> 닭 잡는데 소 잡는 칼을 쓰는 꼴을 설명하는 이미지, 이미지 출처 : https://twitter.com/dev_humor/status/1081973719801712640" src="/static/8b9974b0ab33ef20b6ae7ef594236548/828fb/image09.jpg" srcset="/static/8b9974b0ab33ef20b6ae7ef594236548/ff44c/image09.jpg 158w,
/static/8b9974b0ab33ef20b6ae7ef594236548/a6688/image09.jpg 315w,
/static/8b9974b0ab33ef20b6ae7ef594236548/828fb/image09.jpg 630w,
/static/8b9974b0ab33ef20b6ae7ef594236548/ad059/image09.jpg 758w" sizes="(max-width: 630px) 100vw, 630px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span>
<figcaption>&lt;그림-9&gt; 이미지 출처 : https://twitter.com/dev_humor/status/1081973719801712640/</figcaption>
</figure>
<p>가령 어떤 기업이 내부의 기밀자료를 파인튜닝 시켜서 업무에 활용하고 싶다고 하면, ChatGPT에게 그 자료를 학습시켜서 이용하기는 부담스러울 겁니다. 회사 내부망에서만 접근 가능한 로컬LLM모델을 활용하여 구현하는게 자연스럽죠.</p>
<p>꼭 보안자료가 아니라도 사용량만큼 과금되는 ChatGPT API를 이용하여 서비스를 했을때 그 사용량이 아주 많아진다면 비용상의 문제로도 자신들의 서비스 내에 직접 로컬LLM모델을 사용할 수 밖에 없을 겁니다.</p>
<p>또한 개인이 개인적으로 모델을 파인튜닝하여 사용하고 싶을때도 로컬LLM을 쓰게 될 것이구요.</p>
<p>자꾸 학습, 또는 파인튜닝 이야기가 나와서 요즘 LLM에서 학습이 진행되는 단계에 대해 잠깐 언급해 보도록 할게요.</p>
<p>단계별로 나눠본다면 총 4단계로 나눌 수 있을 것 같아요.</p>
<table>
<thead>
<tr>
<th>분 류</th>
<th>단 계</th>
<th>상세 설명</th>
</tr>
</thead>
<tbody>
<tr>
<td>1단계</td>
<td>사전학습(pretrain)</td>
<td>가능한 많은 데이터를 집어 넣어서 언어를 이해시키는 단계</td>
</tr>
<tr>
<td>2단계</td>
<td>DAPT(Domain Adaptive PreTraining)</td>
<td>활용하고자 하는 도메인에 한정된 데이터를 추가로 학습시켜 해당도메인에 대한 성능을 향상시키는 단계</td>
</tr>
<tr>
<td>3단계</td>
<td>TAPT(Task Adaptive PreTraining)</td>
<td>도메인 내에서도 실제로 하고자 하는 테스크에 맞춘 데이터셋으로 파인튜닝하는 단계</td>
</tr>
<tr>
<td>4단계</td>
<td>미세파인튜닝(personalize)</td>
<td>LORA 같은 추가 튜닝모델을 덧붙여서 개별화 또는 특화시키는 파인튜닝 기법</td>
</tr>
</tbody>
</table>
<p>&#x3C;표-1> LLM에서 학습의 진행단계별 분류</p>
<figure>
<span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; ">
      <a class="gatsby-resp-image-link" href="/static/1bc39813d0060a827294f12774648f60/ad059/image10.jpg" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 70.88607594936708%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAOABQDASIAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAAAAMC/8QAFgEBAQEAAAAAAAAAAAAAAAAAAAED/9oADAMBAAIQAxAAAAHa2WtFCf/EABkQAAIDAQAAAAAAAAAAAAAAAAECAAMREv/aAAgBAQABBQKwvq9RWOMpDYTK6yV//8QAFxEAAwEAAAAAAAAAAAAAAAAAARARIf/aAAgBAwEBPwG5AF//xAAWEQADAAAAAAAAAAAAAAAAAAAQESH/2gAIAQIBAT8BrH//xAAZEAABBQAAAAAAAAAAAAAAAAAAECEiMUH/2gAIAQEABj8CYkWYv//EABoQAAMBAQEBAAAAAAAAAAAAAAABETEhUXH/2gAIAQEAAT8hYa9e0ZVKv0V4bRoXoeqFRUun/9oADAMBAAIAAwAAABCz7//EABkRAQACAwAAAAAAAAAAAAAAAAEAETFBcf/aAAgBAwEBPxBdAdlm8z//xAAZEQADAAMAAAAAAAAAAAAAAAAAAREhMWH/2gAIAQIBAT8QTtqTAun/xAAdEAEAAwABBQAAAAAAAAAAAAABABEhQTFhgdHx/9oACAEBAAE/ELWFUtyvpEFIcw/DndNzKWvyOaXl9RUDWzWf/9k='); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="<그림-10> LLM에서 학습 진행단계별 분류 설명 이미지, 이미지 출처 : JUSTA 제작" title="<그림-10> LLM에서 학습 진행단계별 분류 설명 이미지, 이미지 출처 : JUSTA 제작" src="/static/1bc39813d0060a827294f12774648f60/828fb/image10.jpg" srcset="/static/1bc39813d0060a827294f12774648f60/ff44c/image10.jpg 158w,
/static/1bc39813d0060a827294f12774648f60/a6688/image10.jpg 315w,
/static/1bc39813d0060a827294f12774648f60/828fb/image10.jpg 630w,
/static/1bc39813d0060a827294f12774648f60/ad059/image10.jpg 758w" sizes="(max-width: 630px) 100vw, 630px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span>
<figcaption>&lt;그림-10&gt; LLM에서 학습 진행단계별 분류 설명 이미지, 이미지 출처 : JUSTA 작성</figcaption>
</figure>
<p>정형화된 건 아니지만 이런 단계를 거쳐서 서비스에 활용하게 될 것입니다.</p>
<p>그리고 LLM의 종착역은 맞춤형 인공지능 개인비서가 아닐까 합니다.</p>
<p>인공지능 개인비서 하니 가장 먼저 떠오르는 것은 영화 “아이언맨”의 자비스가 아닐까 싶네요.</p>
<figure>
<span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; ">
      <a class="gatsby-resp-image-link" href="/static/2af1a6a3b098f27752a20aadf7435069/ad059/image11.jpg" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 60.12658227848101%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAMABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAMFAv/EABcBAAMBAAAAAAAAAAAAAAAAAAABAgP/2gAMAwEAAhADEAAAAUbqJHPKZWf/xAAbEAADAAIDAAAAAAAAAAAAAAABAgMABBITFP/aAAgBAQABBQI1p2PSnGZu6nVQp45YNWYH/8QAFxEBAAMAAAAAAAAAAAAAAAAAAAECEf/aAAgBAwEBPwGG2f/EABURAQEAAAAAAAAAAAAAAAAAAAAh/9oACAECAQE/AUf/xAAcEAABBAMBAAAAAAAAAAAAAAAAAQMRIRIxQZH/2gAIAQEABj8ChHFsp3wlHoMLjZ06f//EAB0QAAICAwADAAAAAAAAAAAAAAABEUEhUWExkaH/2gAIAQEAAT8haREtq+Em/DTLIvxHWZIiehdXpHkvY//aAAwDAQACAAMAAAAQcx//xAAXEQADAQAAAAAAAAAAAAAAAAAAASER/9oACAEDAQE/EGlHpMP/xAAWEQEBAQAAAAAAAAAAAAAAAAABADH/2gAIAQIBAT8Qdgv/xAAeEAEBAAEDBQAAAAAAAAAAAAABEQAxUbEhQXGB0f/aAAgBAQABPxBJdOqj2VBziAoiUFdjKdBkm8YUQSI1ZNZgMGt7+emTmF2fM//Z'); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="<그림-11> 그냥 좀 많이 똑똑한 시스템(Just A Rather Very Intelligent System), 이미지 출처 : 미디엄 게시글/디즈니 마블 스튜디오(영화 아이언맨)" title="<그림-11> 그냥 좀 많이 똑똑한 시스템(Just A Rather Very Intelligent System), 이미지 출처 : 미디엄 게시글/디즈니 마블 스튜디오(영화 아이언맨)" src="/static/2af1a6a3b098f27752a20aadf7435069/828fb/image11.jpg" srcset="/static/2af1a6a3b098f27752a20aadf7435069/ff44c/image11.jpg 158w,
/static/2af1a6a3b098f27752a20aadf7435069/a6688/image11.jpg 315w,
/static/2af1a6a3b098f27752a20aadf7435069/828fb/image11.jpg 630w,
/static/2af1a6a3b098f27752a20aadf7435069/ad059/image11.jpg 758w" sizes="(max-width: 630px) 100vw, 630px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span>
<figcaption>&lt;그림-11&gt;그냥 좀 많이 똑똑한 시스템(Just A Rather Very Intelligent System), 이미지 출처 : 미디엄 게시글/디즈니 마블 스튜디오(영화 "아이언맨")</figcaption>
</figure>  
<p>자비스의 어원을 알고 계셨나요? 전 이번에 알아서 좀 충격이었네요.ㅎㅎ</p>
<p>궁극적으로 LLM이 개인비서 형태의 서비스로 발전하게 되면 아무래도 로컬 디바이스에 설치된 로컬서비스 형태로 구현될 것입니다.</p>
<p>영화 “HER” 처럼요.</p>
<figure>
<span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; ">
      <a class="gatsby-resp-image-link" href="/static/784092f145451884ce29b4a769e99439/ad059/image12.jpg" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 43.0379746835443%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAgADBP/EABUBAQEAAAAAAAAAAAAAAAAAAAIB/9oADAMBAAIQAxAAAAHLgRDEKn//xAAbEAACAQUAAAAAAAAAAAAAAAABAgADEBEhMf/aAAgBAQABBQLTKBlZT4Lf/8QAFhEAAwAAAAAAAAAAAAAAAAAAARAx/9oACAEDAQE/ARV//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFhABAQEAAAAAAAAAAAAAAAAAEQEQ/9oACAEBAAY/AqBt3//EABsQAAMAAgMAAAAAAAAAAAAAAAABERBBMXGh/9oACAEBAAE/Ia7WCcjLBztLs8DN8f/aAAwDAQACAAMAAAAQxy//xAAXEQADAQAAAAAAAAAAAAAAAAAAAREh/9oACAEDAQE/EJekU//EABcRAQADAAAAAAAAAAAAAAAAAAABETH/2gAIAQIBAT8QyFP/xAAcEAEAAgMAAwAAAAAAAAAAAAABABEhQVExcfD/2gAIAQEAAT8QEh3TMY2QkNWpVwMkBxT6HJ4e82z/2Q=='); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="<그림-12> 이미지 출처 : 영화 <HER> 장면 중 편집" title="<그림-12> 이미지 출처 : 영화 <HER> 장면 중 편집" src="/static/784092f145451884ce29b4a769e99439/828fb/image12.jpg" srcset="/static/784092f145451884ce29b4a769e99439/ff44c/image12.jpg 158w,
/static/784092f145451884ce29b4a769e99439/a6688/image12.jpg 315w,
/static/784092f145451884ce29b4a769e99439/828fb/image12.jpg 630w,
/static/784092f145451884ce29b4a769e99439/ad059/image12.jpg 758w" sizes="(max-width: 630px) 100vw, 630px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span>
<figcaption>&lt;그림-12&gt; 이미지 출처 : 영화 "HER" 장면 중 편집</figcaption>
</figure>
<h3><strong>4. ChatGPT API를 이용한 서비스 모델</strong></h3>
<p><strong>1) gpt-turbo-3.5, gpt-4 API 사용법</strong></p>
<figure>
<span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; ">
      <a class="gatsby-resp-image-link" href="/static/3019a0c8a61795b7d181e2a070edadf5/ad059/image13.jpg" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 56.32911392405063%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAECBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAe7UNIP/xAAWEAADAAAAAAAAAAAAAAAAAAABIDH/2gAIAQEAAQUCMX//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAYEAEBAAMAAAAAAAAAAAAAAAABABARIf/aAAgBAQABPyHiCsTbx//aAAwDAQACAAMAAAAQAA//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAaEAEAAwADAAAAAAAAAAAAAAABABEhMYGR/9oACAEBAAE/EHrpsAHNlq2uomoI4ryC1P/Z'); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="<그림-13> gpt-turbo-3.5, gpt-4 API 사용법, 이미지 출처 : 
https://platform.openai.com/ 스크린샷" title="<그림-13> gpt-turbo-3.5, gpt-4 API 사용법, 이미지 출처 : 
https://platform.openai.com/ 스크린샷" src="/static/3019a0c8a61795b7d181e2a070edadf5/828fb/image13.jpg" srcset="/static/3019a0c8a61795b7d181e2a070edadf5/ff44c/image13.jpg 158w,
/static/3019a0c8a61795b7d181e2a070edadf5/a6688/image13.jpg 315w,
/static/3019a0c8a61795b7d181e2a070edadf5/828fb/image13.jpg 630w,
/static/3019a0c8a61795b7d181e2a070edadf5/ad059/image13.jpg 758w" sizes="(max-width: 630px) 100vw, 630px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span>
</figure>
<figure>
<span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; ">
      <a class="gatsby-resp-image-link" href="/static/3c9e0f33c674903d2b6317509212807c/ad059/image14.jpg" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 74.68354430379746%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAIBAwQF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAP/aAAwDAQACEAMQAAABl7dRzBg//8QAGhAAAgMBAQAAAAAAAAAAAAAAAQIAAxMQIf/aAAgBAQABBQIKxmb8pcINq43rf//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABoQAQEAAgMAAAAAAAAAAAAAAAEAEBEhMTL/2gAIAQEABj8C4Ly4dt2y3//EABsQAQACAgMAAAAAAAAAAAAAAAEAETFRECFB/9oACAEBAAE/Ibm54ZEacwJYt1Or03UVBhZ//9oADAMBAAIAAwAAABAAD//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABwQAQEBAAIDAQAAAAAAAAAAAAERACFBUYGx0f/aAAgBAQABPxCoDHmda/45MKBiPWWUkkrzgp9x+YXlSjJed//Z'); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="<그림-14> gpt-turbo-3.5, gpt-4 API 사용법, 이미지 출처 : 
https://platform.openai.com/ 스크린샷" title="<그림-14> gpt-turbo-3.5, gpt-4 API 사용법, 이미지 출처 : 
https://platform.openai.com/ 스크린샷" src="/static/3c9e0f33c674903d2b6317509212807c/828fb/image14.jpg" srcset="/static/3c9e0f33c674903d2b6317509212807c/ff44c/image14.jpg 158w,
/static/3c9e0f33c674903d2b6317509212807c/a6688/image14.jpg 315w,
/static/3c9e0f33c674903d2b6317509212807c/828fb/image14.jpg 630w,
/static/3c9e0f33c674903d2b6317509212807c/ad059/image14.jpg 758w" sizes="(max-width: 630px) 100vw, 630px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span>
</figure>  
<p><a href="https://platform.openai.com/">https://platform.openai.com/</a> 이 링크로 들어가셔서 회원가입하고 API 발급받으시면 됩니다.</p>
<ul>
<li>콘솔에서 openai 패키지 설치하여 사용</li>
</ul>
<p>-> pip install openai</p>
<ul>
<li>API 사용한 간단한 예시코드</li>
</ul>
<figure>
<span class="gatsby-resp-image-wrapper" style="position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 630px; ">
      <a class="gatsby-resp-image-link" href="/static/2f97ee12e6364cf2c77b46119ca6134a/4dfa3/image15.jpg" style="display: block" target="_blank" rel="noopener">
    <span class="gatsby-resp-image-background-image" style="padding-bottom: 47.46835443037975%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAJABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAEDBAX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAFbo9MZQP/EABkQAAIDAQAAAAAAAAAAAAAAAAACAQMRMv/aAAgBAQABBQJdK7JUhtgTg//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABoQAAICAwAAAAAAAAAAAAAAAAABEDEzQYH/2gAIAQEABj8C0Y1wqFH/xAAbEAEBAQACAwAAAAAAAAAAAAABEQAQQXGRof/aAAgBAQABPyG1QXmaGQO1Gew/Zx8+N//aAAwDAQACAAMAAAAQYA//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAdEAACAgIDAQAAAAAAAAAAAAAAAREhMWFBcaHR/9oACAEBAAE/EEY3Jau3OxAhrc2e8la+Yv6DyuzyzA//2Q=='); background-size: cover; display: block;"></span>
  <img class="gatsby-resp-image-image" alt="<그림-15> API 사용한 간단한 예시코드, 이미지 출처 : JUSTA 작성" title="<그림-15> API 사용한 간단한 예시코드, 이미지 출처 : JUSTA 작성" src="/static/2f97ee12e6364cf2c77b46119ca6134a/828fb/image15.jpg" srcset="/static/2f97ee12e6364cf2c77b46119ca6134a/ff44c/image15.jpg 158w,
/static/2f97ee12e6364cf2c77b46119ca6134a/a6688/image15.jpg 315w,
/static/2f97ee12e6364cf2c77b46119ca6134a/828fb/image15.jpg 630w,
/static/2f97ee12e6364cf2c77b46119ca6134a/4dfa3/image15.jpg 792w" sizes="(max-width: 630px) 100vw, 630px" style="width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;" loading="lazy" decoding="async">
  </a>
    </span>
<figcaption>&lt;그림-15&gt; API 사용한 간단한 예시코드, 출처 : JUSTA 작성 </figcaption>
</figure>
<p><strong>2) API를 이용한 응용서비스</strong></p>
<ol>
<li>PDF화일을 분석요약하고 질문에 대답</li>
</ol>
<p><a href="https://www.chatpdf.com/">https://www.chatpdf.com/</a>
2. Excel화일을 분석요약하고 질문에 대답<br>
<a href="https://chatexcel.com/en">https://chatexcel.com/en</a>
3. chatGPT동화생성 - 미드저니 삽화생성 - ebook제작툴<br>
<a href="https://www.youtube.com/watch?v=-79WCOE4Q28">https://www.youtube.com/watch?v=-79WCOE4Q28</a>
4. chatGPT로 영어공부<br>
<a href="https://www.youtube.com/watch?v=HLxlKtEAL5U">https://www.youtube.com/watch?v=HLxlKtEAL5U</a>
5. chatGPT를 이용한 NPC 캐릭터 및 자유대화 모델<br>
<a href="https://www.youtube.com/watch?v=UVNZ3_FwqJE">https://www.youtube.com/watch?v=UVNZ3_FwqJE</a>
<a href="https://youtu.be/U4W2rGH9oWs">https://youtu.be/U4W2rGH9oWs</a>  ChatGPT NPC coaches me talking to people at a party in VR</p>
<p>이상 세미나 내용 중 언론 분야에 특화된 내용을 제외한 부분을 정리해 보았습니다.</p>
<p>인공지능 분야는 다 그렇지만, 특히 LLM은 요즘 하루가 다르게 기술이 발전하고 있습니다. 작년에 Stable Diffusion이 엄청 핫했던 것처럼요.</p>
<p>이 글을 정리하는 중에도 LLM의 할루시네이션을 줄이는 방법이나 개별 레이어의 파라미터값이 의미하는 바를 추적하여 개별튜닝이 가능한 기법 등 신기술들이 튀어나오고 있습니다.</p>
<p>틈나는대로 시리즈 같은 느낌적 느낌으로 후속 글을 계속 작성해 보겠습니다.</p>
<p>감사합니다.</p></section><hr/><footer><div class="bio"><img class="bio-avatar" src="../images/Justa.png" width="50" height="50" alt=""/><p>작성자 <strong>Justa</strong></p></div></footer></article><nav class="blog-post-nav"><ul style="display:flex;flex-wrap:wrap;justify-content:space-between;list-style:none;padding:0"><li><a rel="prev" href="/2023-06-02-FP/">← <!-- -->기능점수(Function Point) 기본 개념과 산정방식</a></li><li><a rel="next" href="/2023-08-31-Advice-for-Project-Manager/">서비스 기획자의 성장을 돕는 역량 강화 팁; 성공을 이끄는 비밀 노하우<!-- --> →</a></li></ul></nav></main><footer><p class="copyright">© MediaNavi</p></footer></div></div><div id="gatsby-announcer" style="position:absolute;top:0;width:1px;height:1px;padding:0;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border:0" aria-live="assertive" aria-atomic="true"></div></div><script id="gatsby-script-loader">/*<![CDATA[*/window.pagePath="/2023-06-20-Stream-of-NLP/";window.___webpackCompilationHash="f8caf2253b1a6c7714c9";/*]]>*/</script><script id="gatsby-chunk-mapping">/*<![CDATA[*/window.___chunkMapping={"app":["/app-90c1351ed6738eeedfbb.js"],"component---src-pages-404-js":["/component---src-pages-404-js-ac989e24304a34f67e47.js"],"component---src-pages-index-js":["/component---src-pages-index-js-2c4d359f6f501ded91cb.js"],"component---src-pages-works-js":["/component---src-pages-works-js-beb11e784d78eadba7dc.js"],"component---src-templates-blog-post-js":["/component---src-templates-blog-post-js-3b9ccc2046bedbfe9991.js"]};/*]]>*/</script><script src="/app-90c1351ed6738eeedfbb.js" async=""></script><script src="/framework-1e99f3a671b040f20568.js" async=""></script><script src="/webpack-runtime-f59dd854d445c0e46e1c.js" async=""></script></body></html>